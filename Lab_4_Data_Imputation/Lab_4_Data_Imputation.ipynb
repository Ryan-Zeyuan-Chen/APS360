{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Lab_4_Data_Imputation.ipynb","provenance":[],"collapsed_sections":["HwjDg1uM1pqe","OEJ0Ci3l1pqh","1_5ZZR_J1pqy","WKk01pwx1pq_","SxCTlXoV1prB","h9xTwIf51prF","UEe9yt6L1prM","QlHu0wxh1prP","DfQPgu1Q1prS","p_d5uuAY1prZ","fdLNA0ce1prd"],"toc_visible":true},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.4"}},"cells":[{"cell_type":"markdown","metadata":{"id":"OhtOdxzd1ppr"},"source":["# Lab 4: Data Imputation using an Autoencoder\n","\n","**Deadline**: June 11, 11:59pm\n","\n","**Late Penalty**: There is a penalty-free grace period of one hour past the deadline. Any work that is submitted between 1 hour and 24 hours past the deadline will receive a 20% grade deduction. No other late work is accepted. Quercus submission time will be used, not your local computer time. You can submit your labs as many times as you want before the deadline, so please submit often and early.\n","\n","In this lab, you will build and train an autoencoder to impute (or \"fill in\") missing data. \n","\n","We will be using the\n","Adult Data Set provided by the UCI Machine Learning Repository [1], available \n","at https://archive.ics.uci.edu/ml/datasets/adult.\n","The data set contains census record files of adults, including their\n","age, martial status, the type of work they do, and other features. \n","\n","Normally, people use this data set to build a supervised classification\n","model to classify whether a person is a high income earner.\n","We will not use the dataset for this original intended purpose.\n","\n","Instead, we will perform the task of imputing (or \"filling in\") missing values in the dataset. For example,\n","we may be missing one person's martial status, and another person's age, and\n","a third person's level of education. Our model will predict the missing features \n","based on the information that we do have about each person.\n","\n","We will use a variation of a denoising autoencoder to solve this data imputation\n","problem. Our autoencoder will be trained using inputs that have one categorical feature artificially\n","removed, and the goal of the autoencoder is to correctly reconstruct all features,\n","including the one removed from the input.\n","\n","In the process, you are expected to learn to:\n","\n","1. Clean and process continuous and categorical data for machine learning.\n","2. Implement an autoencoder that takes continuous and categorical (one-hot) inputs.\n","3. Tune the hyperparameters of an autoencoder.\n","4. Use baseline models to help interpret model performance.\n","\n","[1] Dua, D. and Karra Taniskidou, E. (2017). UCI Machine Learning Repository [http://archive.ics.uci.edu/ml]. Irvine, CA: University of California, School of Information and Computer Science.\n","\n","\n","### What to submit\n","\n","Submit a PDF file containing all your code, outputs, and write-up. You can produce a PDF of your Google Colab file by going to File > Print and then save as PDF. The Colab instructions have more information (.html files are also acceptable).\n","\n","Do not submit any other files produced by your code.\n","\n","Include a link to your colab file in your submission.\n"]},{"cell_type":"markdown","metadata":{"id":"zbnrp2ig1pps"},"source":["## Colab Link\n","\n","Include a link to your Colab file here. If you would like the TA to look at your\n","Colab file in case your solutions are cut off, **please make sure that your Colab\n","file is publicly accessible at the time of submission**.\n","\n","Colab Link: https://drive.google.com/file/d/14siiGm5gAhLp9rs4D3HDoa3OfXdcsVIC/view?usp=sharing"]},{"cell_type":"code","metadata":{"id":"z3p8N43E1ppt"},"source":["import csv\n","import numpy as np\n","import random\n","import torch\n","import torch.utils.data\n","import time\n","import matplotlib.pyplot as plt"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"8ROwtHcz1ppx"},"source":["## Part 0\n","\n","We will be using a package called `pandas` for this assignment. \n","\n","If you are using Colab, `pandas` should already be available.\n","If you are using your own computer,\n","installation instructions for `pandas` are available here: \n","https://pandas.pydata.org/pandas-docs/stable/install.html"]},{"cell_type":"code","metadata":{"id":"IXQ7BP151ppz"},"source":["import pandas as pd"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"hqXihb4Q1pp2"},"source":["# Part 1. Data Cleaning [15 pt]\n","\n","The adult.data file is available at `https://archive.ics.uci.edu/ml/machine-learning-databases/adult/adult.data`\n","\n","The function `pd.read_csv` loads the adult.data file into a pandas dataframe.\n","You can read about the pandas documentation for `pd.read_csv` at\n","https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.read_csv.html"]},{"cell_type":"code","metadata":{"id":"EOMItFKn1pp3"},"source":["header = ['age', 'work', 'fnlwgt', 'edu', 'yredu', 'marriage', 'occupation',\n"," 'relationship', 'race', 'sex', 'capgain', 'caploss', 'workhr', 'country']\n","df = pd.read_csv(\n","    \"https://archive.ics.uci.edu/ml/machine-learning-databases/adult/adult.data\",\n","    names=header,\n","    index_col=False)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"62Ot405q1pp5","scrolled":true,"executionInfo":{"status":"ok","timestamp":1623459912242,"user_tz":240,"elapsed":125,"user":{"displayName":"Ryan Chen","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiEvvD9_5qPytyzMTOpfMHuCrDH24wjoy50AGq6UQ=s64","userId":"16436951824151695317"}},"outputId":"28d1aa19-afca-4549-886c-88a28a38e3a3"},"source":["df.shape # there are 32561 rows (records) in the data frame, and 14 columns (features)"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(32561, 14)"]},"metadata":{"tags":[]},"execution_count":90}]},{"cell_type":"markdown","metadata":{"id":"Tr7YG-QY1pp8"},"source":["### Part (a) Continuous Features [3 pt]\n","\n","For each of the columns `[\"age\", \"yredu\", \"capgain\", \"caploss\", \"workhr\"]`, report the minimum, maximum, and average value across the dataset. \n","\n","Then, normalize each of the features `[\"age\", \"yredu\", \"capgain\", \"caploss\", \"workhr\"]`\n","so that their values are always between 0 and 1.\n","Make sure that you are actually modifying the dataframe `df`. \n","\n","Like numpy arrays and torch tensors, \n","pandas data frames can be sliced. For example, we can\n","display the first 3 rows of the data frame (3 records) below."]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":142},"id":"9evSLsSa1pp9","scrolled":false,"executionInfo":{"status":"ok","timestamp":1623459914936,"user_tz":240,"elapsed":123,"user":{"displayName":"Ryan Chen","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiEvvD9_5qPytyzMTOpfMHuCrDH24wjoy50AGq6UQ=s64","userId":"16436951824151695317"}},"outputId":"55c88269-da26-4163-8eba-1bf10ee34fe4"},"source":["df[:3] # show the first 3 records"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>age</th>\n","      <th>work</th>\n","      <th>fnlwgt</th>\n","      <th>edu</th>\n","      <th>yredu</th>\n","      <th>marriage</th>\n","      <th>occupation</th>\n","      <th>relationship</th>\n","      <th>race</th>\n","      <th>sex</th>\n","      <th>capgain</th>\n","      <th>caploss</th>\n","      <th>workhr</th>\n","      <th>country</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>39</td>\n","      <td>State-gov</td>\n","      <td>77516</td>\n","      <td>Bachelors</td>\n","      <td>13</td>\n","      <td>Never-married</td>\n","      <td>Adm-clerical</td>\n","      <td>Not-in-family</td>\n","      <td>White</td>\n","      <td>Male</td>\n","      <td>2174</td>\n","      <td>0</td>\n","      <td>40</td>\n","      <td>United-States</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>50</td>\n","      <td>Self-emp-not-inc</td>\n","      <td>83311</td>\n","      <td>Bachelors</td>\n","      <td>13</td>\n","      <td>Married-civ-spouse</td>\n","      <td>Exec-managerial</td>\n","      <td>Husband</td>\n","      <td>White</td>\n","      <td>Male</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>13</td>\n","      <td>United-States</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>38</td>\n","      <td>Private</td>\n","      <td>215646</td>\n","      <td>HS-grad</td>\n","      <td>9</td>\n","      <td>Divorced</td>\n","      <td>Handlers-cleaners</td>\n","      <td>Not-in-family</td>\n","      <td>White</td>\n","      <td>Male</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>40</td>\n","      <td>United-States</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["   age               work  fnlwgt  ... caploss  workhr         country\n","0   39          State-gov   77516  ...       0      40   United-States\n","1   50   Self-emp-not-inc   83311  ...       0      13   United-States\n","2   38            Private  215646  ...       0      40   United-States\n","\n","[3 rows x 14 columns]"]},"metadata":{"tags":[]},"execution_count":91}]},{"cell_type":"markdown","metadata":{"id":"gBOojI6W1pqA"},"source":["Alternatively, we can slice based on column names, \n","for example `df[\"race\"]`, `df[\"hr\"]`, or even index multiple columns \n","like below."]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":142},"id":"4v6pp73A1pqB","executionInfo":{"status":"ok","timestamp":1623445989336,"user_tz":240,"elapsed":135,"user":{"displayName":"Ryan Chen","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiEvvD9_5qPytyzMTOpfMHuCrDH24wjoy50AGq6UQ=s64","userId":"16436951824151695317"}},"outputId":"93170b84-c7b5-4d73-9b66-dd14c52b96ca"},"source":["subdf = df[[\"age\", \"yredu\", \"capgain\", \"caploss\", \"workhr\"]]\n","subdf[:3] # show the first 3 records"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>age</th>\n","      <th>yredu</th>\n","      <th>capgain</th>\n","      <th>caploss</th>\n","      <th>workhr</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>39</td>\n","      <td>13</td>\n","      <td>2174</td>\n","      <td>0</td>\n","      <td>40</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>50</td>\n","      <td>13</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>13</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>38</td>\n","      <td>9</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>40</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["   age  yredu  capgain  caploss  workhr\n","0   39     13     2174        0      40\n","1   50     13        0        0      13\n","2   38      9        0        0      40"]},"metadata":{"tags":[]},"execution_count":7}]},{"cell_type":"markdown","metadata":{"id":"2Nru2P0E1pqD"},"source":["Numpy works nicely with pandas, like below:"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"JXrS6tjp1pqE","executionInfo":{"status":"ok","timestamp":1623445991691,"user_tz":240,"elapsed":124,"user":{"displayName":"Ryan Chen","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiEvvD9_5qPytyzMTOpfMHuCrDH24wjoy50AGq6UQ=s64","userId":"16436951824151695317"}},"outputId":"4e65d411-68e1-4789-b7d0-a9f62269dcf6"},"source":["np.sum(subdf[\"caploss\"])"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["2842700"]},"metadata":{"tags":[]},"execution_count":8}]},{"cell_type":"markdown","metadata":{"id":"Mv5mbxDM1pqH"},"source":["Just like numpy arrays, you can modify\n","entire columns of data rather than one scalar element at a time.\n","For example, the code  \n","\n","`df[\"age\"] = df[\"age\"] + 1` \n","\n","would increment everyone's age by 1."]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"k5rlWD7-1pqH","executionInfo":{"status":"ok","timestamp":1623445994021,"user_tz":240,"elapsed":111,"user":{"displayName":"Ryan Chen","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiEvvD9_5qPytyzMTOpfMHuCrDH24wjoy50AGq6UQ=s64","userId":"16436951824151695317"}},"outputId":"1f20c1b7-682f-4e11-f6c0-f19a3a8882ac"},"source":["print(\"The minimum values of each column are:\")\n","subdf.min()"],"execution_count":null,"outputs":[{"output_type":"stream","text":["The minimum values of each column are:\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/plain":["age        17\n","yredu       1\n","capgain     0\n","caploss     0\n","workhr      1\n","dtype: int64"]},"metadata":{"tags":[]},"execution_count":9}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"4PtCNhLfNDRJ","executionInfo":{"status":"ok","timestamp":1623445996032,"user_tz":240,"elapsed":110,"user":{"displayName":"Ryan Chen","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiEvvD9_5qPytyzMTOpfMHuCrDH24wjoy50AGq6UQ=s64","userId":"16436951824151695317"}},"outputId":"6830479e-d414-4551-afef-50d9d9be9894"},"source":["print(\"The maximum values of each column are:\")\n","subdf.max()"],"execution_count":null,"outputs":[{"output_type":"stream","text":["The maximum values of each column are:\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/plain":["age           90\n","yredu         16\n","capgain    99999\n","caploss     4356\n","workhr        99\n","dtype: int64"]},"metadata":{"tags":[]},"execution_count":10}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Ie_qoUE9NWqu","executionInfo":{"status":"ok","timestamp":1623445998772,"user_tz":240,"elapsed":152,"user":{"displayName":"Ryan Chen","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiEvvD9_5qPytyzMTOpfMHuCrDH24wjoy50AGq6UQ=s64","userId":"16436951824151695317"}},"outputId":"1104f76f-f56f-4db2-e84e-55ff3e5e9447"},"source":["print(\"The average values of each column are:\")\n","subdf.mean()"],"execution_count":null,"outputs":[{"output_type":"stream","text":["The average values of each column are:\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/plain":["age          38.581647\n","yredu        10.080679\n","capgain    1077.648844\n","caploss      87.303830\n","workhr       40.437456\n","dtype: float64"]},"metadata":{"tags":[]},"execution_count":11}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":159},"id":"_CuM8rX8Or2g","executionInfo":{"status":"ok","timestamp":1623459941894,"user_tz":240,"elapsed":128,"user":{"displayName":"Ryan Chen","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiEvvD9_5qPytyzMTOpfMHuCrDH24wjoy50AGq6UQ=s64","userId":"16436951824151695317"}},"outputId":"86067e15-a4e9-4f5a-d1d3-a0421745d212"},"source":["df[[\"age\", \"yredu\", \"capgain\", \"caploss\", \"workhr\"]] = (subdf - subdf.min())/(subdf.max() - subdf.min())\n","print(\"The first 3 records of the normalized data set are:\")\n","df[:3] # show the first 3 records"],"execution_count":null,"outputs":[{"output_type":"stream","text":["The first 3 records of the normalized data set are:\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>age</th>\n","      <th>work</th>\n","      <th>fnlwgt</th>\n","      <th>edu</th>\n","      <th>yredu</th>\n","      <th>marriage</th>\n","      <th>occupation</th>\n","      <th>relationship</th>\n","      <th>race</th>\n","      <th>sex</th>\n","      <th>capgain</th>\n","      <th>caploss</th>\n","      <th>workhr</th>\n","      <th>country</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>0.301370</td>\n","      <td>State-gov</td>\n","      <td>77516</td>\n","      <td>Bachelors</td>\n","      <td>0.800000</td>\n","      <td>Never-married</td>\n","      <td>Adm-clerical</td>\n","      <td>Not-in-family</td>\n","      <td>White</td>\n","      <td>Male</td>\n","      <td>0.02174</td>\n","      <td>0.0</td>\n","      <td>0.397959</td>\n","      <td>United-States</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>0.452055</td>\n","      <td>Self-emp-not-inc</td>\n","      <td>83311</td>\n","      <td>Bachelors</td>\n","      <td>0.800000</td>\n","      <td>Married-civ-spouse</td>\n","      <td>Exec-managerial</td>\n","      <td>Husband</td>\n","      <td>White</td>\n","      <td>Male</td>\n","      <td>0.00000</td>\n","      <td>0.0</td>\n","      <td>0.122449</td>\n","      <td>United-States</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>0.287671</td>\n","      <td>Private</td>\n","      <td>215646</td>\n","      <td>HS-grad</td>\n","      <td>0.533333</td>\n","      <td>Divorced</td>\n","      <td>Handlers-cleaners</td>\n","      <td>Not-in-family</td>\n","      <td>White</td>\n","      <td>Male</td>\n","      <td>0.00000</td>\n","      <td>0.0</td>\n","      <td>0.397959</td>\n","      <td>United-States</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["        age               work  fnlwgt  ... caploss    workhr         country\n","0  0.301370          State-gov   77516  ...     0.0  0.397959   United-States\n","1  0.452055   Self-emp-not-inc   83311  ...     0.0  0.122449   United-States\n","2  0.287671            Private  215646  ...     0.0  0.397959   United-States\n","\n","[3 rows x 14 columns]"]},"metadata":{"tags":[]},"execution_count":92}]},{"cell_type":"markdown","metadata":{"id":"qbfMly4R1pqK"},"source":["### Part (b) Categorical Features [1 pt]\n","\n","What percentage of people in our data set are male? Note that the data labels all have an unfortunate space in the beginning, e.g. \" Male\" instead of \"Male\".\n","\n","What percentage of people in our data set are female?"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"DjAjcsB_1pqK","executionInfo":{"status":"ok","timestamp":1623459959679,"user_tz":240,"elapsed":143,"user":{"displayName":"Ryan Chen","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiEvvD9_5qPytyzMTOpfMHuCrDH24wjoy50AGq6UQ=s64","userId":"16436951824151695317"}},"outputId":"b6658a37-82f7-475a-cb11-51d33437d559"},"source":["# hint: you can do something like this in pandas\n","male_size = sum(df[\"sex\"] == \" Male\")\n","female_size = sum(df[\"sex\"] == \" Female\")\n","sex_size = df[\"sex\"].size\n","\n","print(male_size/sex_size*100, \"% of people in the data set are male.\")\n","print(female_size/sex_size*100, \"% of people in the data set are female.\")"],"execution_count":null,"outputs":[{"output_type":"stream","text":["66.92054912318419 % of people in the data set are male.\n","33.07945087681583 % of people in the data set are female.\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"eGVw7pqL1pqN"},"source":["### Part (c) [2 pt]\n","\n","Before proceeding, we will modify our data frame in a couple more ways:\n","\n","1. We will restrict ourselves to using a subset of the features (to simplify our autoencoder)\n","2. We will remove any records (rows) already containing missing values, and store them in a second dataframe. We will only use records without missing values to train our autoencoder.\n","\n","Both of these steps are done for you, below.\n","\n","How many records contained missing features? What percentage of records were removed?"]},{"cell_type":"code","metadata":{"id":"z6ewPUdv1pqO"},"source":["contcols = [\"age\", \"yredu\", \"capgain\", \"caploss\", \"workhr\"]\n","catcols = [\"work\", \"marriage\", \"occupation\", \"edu\", \"relationship\", \"sex\"]\n","features = contcols + catcols\n","df = df[features]"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"fjdVll5a1pqQ"},"source":["missing = pd.concat([df[c] == \" ?\" for c in catcols], axis=1).any(axis=1)\n","df_with_missing = df[missing]\n","df_not_missing = df[~missing]"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"qzCYQuk1RRdh","executionInfo":{"status":"ok","timestamp":1623459965879,"user_tz":240,"elapsed":139,"user":{"displayName":"Ryan Chen","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiEvvD9_5qPytyzMTOpfMHuCrDH24wjoy50AGq6UQ=s64","userId":"16436951824151695317"}},"outputId":"95a8d0d2-3217-4210-be4e-40b55a320863"},"source":["missing_size = df_with_missing.shape[0]\n","total_size = df.shape[0]\n","\n","print(missing_size, \"records contained missing features.\")\n","print(missing_size/total_size*100, \"% of records were removed.\")"],"execution_count":null,"outputs":[{"output_type":"stream","text":["1843 records contained missing features.\n","5.660145572924664 % of records were removed.\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"XuEpndTQ1pqU"},"source":["### Part (d) One-Hot Encoding [1 pt]\n","\n","What are all the possible values of the feature \"work\" in `df_not_missing`? You may find the Python function `set` useful."]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"iKFh4owE1pqV","executionInfo":{"status":"ok","timestamp":1623459968890,"user_tz":240,"elapsed":124,"user":{"displayName":"Ryan Chen","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiEvvD9_5qPytyzMTOpfMHuCrDH24wjoy50AGq6UQ=s64","userId":"16436951824151695317"}},"outputId":"34bb77d8-8378-48cd-f224-013344bcfe34"},"source":["work_values = set(df_not_missing[\"work\"])\n","\n","print(\"The possible values of the feature \\\"work\\\" are:\")\n","for work in work_values:\n","    print(work)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["The possible values of the feature \"work\" are:\n"," Local-gov\n"," Without-pay\n"," Private\n"," State-gov\n"," Self-emp-not-inc\n"," Self-emp-inc\n"," Federal-gov\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"COv3HaKr1pqY"},"source":["We will be using a one-hot encoding to represent each of the categorical variables.\n","Our autoencoder will be trained using these one-hot encodings.\n","\n","We will use the pandas function `get_dummies` to produce one-hot encodings\n","for all of the categorical variables in `df_not_missing`. "]},{"cell_type":"code","metadata":{"id":"eKlSYmJg1pqZ"},"source":["data = pd.get_dummies(df_not_missing)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":230},"id":"3y7nTZ7H1pqb","scrolled":true,"executionInfo":{"status":"ok","timestamp":1623459974162,"user_tz":240,"elapsed":143,"user":{"displayName":"Ryan Chen","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiEvvD9_5qPytyzMTOpfMHuCrDH24wjoy50AGq6UQ=s64","userId":"16436951824151695317"}},"outputId":"2f51994c-8cec-4413-aa7a-265110523824"},"source":["data[:3]"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>age</th>\n","      <th>yredu</th>\n","      <th>capgain</th>\n","      <th>caploss</th>\n","      <th>workhr</th>\n","      <th>work_ Federal-gov</th>\n","      <th>work_ Local-gov</th>\n","      <th>work_ Private</th>\n","      <th>work_ Self-emp-inc</th>\n","      <th>work_ Self-emp-not-inc</th>\n","      <th>work_ State-gov</th>\n","      <th>work_ Without-pay</th>\n","      <th>marriage_ Divorced</th>\n","      <th>marriage_ Married-AF-spouse</th>\n","      <th>marriage_ Married-civ-spouse</th>\n","      <th>marriage_ Married-spouse-absent</th>\n","      <th>marriage_ Never-married</th>\n","      <th>marriage_ Separated</th>\n","      <th>marriage_ Widowed</th>\n","      <th>occupation_ Adm-clerical</th>\n","      <th>occupation_ Armed-Forces</th>\n","      <th>occupation_ Craft-repair</th>\n","      <th>occupation_ Exec-managerial</th>\n","      <th>occupation_ Farming-fishing</th>\n","      <th>occupation_ Handlers-cleaners</th>\n","      <th>occupation_ Machine-op-inspct</th>\n","      <th>occupation_ Other-service</th>\n","      <th>occupation_ Priv-house-serv</th>\n","      <th>occupation_ Prof-specialty</th>\n","      <th>occupation_ Protective-serv</th>\n","      <th>occupation_ Sales</th>\n","      <th>occupation_ Tech-support</th>\n","      <th>occupation_ Transport-moving</th>\n","      <th>edu_ 10th</th>\n","      <th>edu_ 11th</th>\n","      <th>edu_ 12th</th>\n","      <th>edu_ 1st-4th</th>\n","      <th>edu_ 5th-6th</th>\n","      <th>edu_ 7th-8th</th>\n","      <th>edu_ 9th</th>\n","      <th>edu_ Assoc-acdm</th>\n","      <th>edu_ Assoc-voc</th>\n","      <th>edu_ Bachelors</th>\n","      <th>edu_ Doctorate</th>\n","      <th>edu_ HS-grad</th>\n","      <th>edu_ Masters</th>\n","      <th>edu_ Preschool</th>\n","      <th>edu_ Prof-school</th>\n","      <th>edu_ Some-college</th>\n","      <th>relationship_ Husband</th>\n","      <th>relationship_ Not-in-family</th>\n","      <th>relationship_ Other-relative</th>\n","      <th>relationship_ Own-child</th>\n","      <th>relationship_ Unmarried</th>\n","      <th>relationship_ Wife</th>\n","      <th>sex_ Female</th>\n","      <th>sex_ Male</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>0.301370</td>\n","      <td>0.800000</td>\n","      <td>0.02174</td>\n","      <td>0.0</td>\n","      <td>0.397959</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>0.452055</td>\n","      <td>0.800000</td>\n","      <td>0.00000</td>\n","      <td>0.0</td>\n","      <td>0.122449</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>0.287671</td>\n","      <td>0.533333</td>\n","      <td>0.00000</td>\n","      <td>0.0</td>\n","      <td>0.397959</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["        age     yredu  capgain  ...  relationship_ Wife  sex_ Female  sex_ Male\n","0  0.301370  0.800000  0.02174  ...                   0            0          1\n","1  0.452055  0.800000  0.00000  ...                   0            0          1\n","2  0.287671  0.533333  0.00000  ...                   0            0          1\n","\n","[3 rows x 57 columns]"]},"metadata":{"tags":[]},"execution_count":99}]},{"cell_type":"markdown","metadata":{"id":"HwjDg1uM1pqe"},"source":["### Part (e) One-Hot Encoding [2 pt]\n","\n","The dataframe `data` contains the cleaned and normalized data that we will use to train our denoising autoencoder.\n","\n","How many **columns** (features) are in the dataframe `data`?\n","\n","Briefly explain where that number come from."]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"yjZ5N0Tl1pqf","executionInfo":{"status":"ok","timestamp":1623459995444,"user_tz":240,"elapsed":117,"user":{"displayName":"Ryan Chen","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiEvvD9_5qPytyzMTOpfMHuCrDH24wjoy50AGq6UQ=s64","userId":"16436951824151695317"}},"outputId":"c7001001-f1dd-4ef8-bd3e-683d0243ddb2"},"source":["data.shape[1]"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["57"]},"metadata":{"tags":[]},"execution_count":100}]},{"cell_type":"code","metadata":{"id":"sHK5VhX4Vfey"},"source":["total_cols = 0\n","for feature in catcols:\n","    total_cols += len(set(df_not_missing[feature]))\n","total_cols += len(contcols)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"zk_rIG-FWfzn","executionInfo":{"status":"ok","timestamp":1623459998996,"user_tz":240,"elapsed":134,"user":{"displayName":"Ryan Chen","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiEvvD9_5qPytyzMTOpfMHuCrDH24wjoy50AGq6UQ=s64","userId":"16436951824151695317"}},"outputId":"606f43b5-0a2e-4a1d-a605-a687c19a1542"},"source":["total_cols"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["57"]},"metadata":{"tags":[]},"execution_count":102}]},{"cell_type":"markdown","metadata":{"id":"g1Z_mt6VWhur"},"source":["**Answer:**\n","\n","As shown in the code above, 57 columns (features) are in the dataframe `data`. The number comes from the sum of all continuous features and all possible values of each categorical feature. "]},{"cell_type":"markdown","metadata":{"id":"OEJ0Ci3l1pqh"},"source":["### Part (f) One-Hot Conversion [3 pt]\n","\n","We will convert the pandas data frame `data` into numpy, so that\n","it can be further converted into a PyTorch tensor.\n","However, in doing so, we lose the column label information that\n","a panda data frame automatically stores.\n","\n","Complete the function `get_categorical_value` that will return\n","the named value of a feature given a one-hot embedding.\n","You may find the global variables `cat_index` and `cat_values`\n","useful. (Display them and figure out what they are first.)\n","\n","We will need this function in the next part of the lab\n","to interpret our autoencoder outputs. So, the input\n","to our function `get_categorical_values` might not \n","actually be \"one-hot\" -- the input may instead \n","contain real-valued predictions from our neural network."]},{"cell_type":"code","metadata":{"id":"ZmovX6gu1pqi"},"source":["datanp = data.values.astype(np.float32)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"fCpSU8k1oMXA"},"source":["cat_index = {}  # Mapping of feature -> start index of feature in a record\n","cat_values = {} # Mapping of feature -> list of categorical values the feature can take\n","\n","# build up the cat_index and cat_values dictionary\n","for i, header in enumerate(data.keys()):\n","    if \"_\" in header: # categorical header\n","        feature, value = header.split()\n","        feature = feature[:-1] # remove the last char; it is always an underscore\n","        if feature not in cat_index:\n","            cat_index[feature] = i\n","            cat_values[feature] = [value]\n","        else:\n","            cat_values[feature].append(value)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"iwxOykf4oOKB","executionInfo":{"status":"ok","timestamp":1623460013693,"user_tz":240,"elapsed":148,"user":{"displayName":"Ryan Chen","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiEvvD9_5qPytyzMTOpfMHuCrDH24wjoy50AGq6UQ=s64","userId":"16436951824151695317"}},"outputId":"2e6d2f50-6096-4bbb-8a4d-829d7978b6ed"},"source":["cat_index"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["{'edu': 33,\n"," 'marriage': 12,\n"," 'occupation': 19,\n"," 'relationship': 49,\n"," 'sex': 55,\n"," 'work': 5}"]},"metadata":{"tags":[]},"execution_count":105}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"knO0HpqeoQzm","executionInfo":{"status":"ok","timestamp":1623460016213,"user_tz":240,"elapsed":187,"user":{"displayName":"Ryan Chen","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiEvvD9_5qPytyzMTOpfMHuCrDH24wjoy50AGq6UQ=s64","userId":"16436951824151695317"}},"outputId":"975b5e45-d1b1-4d68-8dcf-b5ceecc88a65"},"source":["cat_values"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["{'edu': ['10th',\n","  '11th',\n","  '12th',\n","  '1st-4th',\n","  '5th-6th',\n","  '7th-8th',\n","  '9th',\n","  'Assoc-acdm',\n","  'Assoc-voc',\n","  'Bachelors',\n","  'Doctorate',\n","  'HS-grad',\n","  'Masters',\n","  'Preschool',\n","  'Prof-school',\n","  'Some-college'],\n"," 'marriage': ['Divorced',\n","  'Married-AF-spouse',\n","  'Married-civ-spouse',\n","  'Married-spouse-absent',\n","  'Never-married',\n","  'Separated',\n","  'Widowed'],\n"," 'occupation': ['Adm-clerical',\n","  'Armed-Forces',\n","  'Craft-repair',\n","  'Exec-managerial',\n","  'Farming-fishing',\n","  'Handlers-cleaners',\n","  'Machine-op-inspct',\n","  'Other-service',\n","  'Priv-house-serv',\n","  'Prof-specialty',\n","  'Protective-serv',\n","  'Sales',\n","  'Tech-support',\n","  'Transport-moving'],\n"," 'relationship': ['Husband',\n","  'Not-in-family',\n","  'Other-relative',\n","  'Own-child',\n","  'Unmarried',\n","  'Wife'],\n"," 'sex': ['Female', 'Male'],\n"," 'work': ['Federal-gov',\n","  'Local-gov',\n","  'Private',\n","  'Self-emp-inc',\n","  'Self-emp-not-inc',\n","  'State-gov',\n","  'Without-pay']}"]},"metadata":{"tags":[]},"execution_count":106}]},{"cell_type":"code","metadata":{"id":"YRIa5MBd1pql"},"source":["def get_onehot(record, feature):\n","    \"\"\"\n","    Return the portion of `record` that is the one-hot encoding\n","    of `feature`. For example, since the feature \"work\" is stored\n","    in the indices [5:12] in each record, calling `get_range(record, \"work\")`\n","    is equivalent to accessing `record[5:12]`.\n","    \n","    Args:\n","        - record: a numpy array representing one record, formatted\n","                  the same way as a row in `data.np`\n","        - feature: a string, should be an element of `catcols`\n","    \"\"\"\n","    start_index = cat_index[feature]\n","    stop_index = cat_index[feature] + len(cat_values[feature])\n","    return record[start_index:stop_index]\n","\n","def get_categorical_value(onehot, feature):\n","    \"\"\"\n","    Return the categorical value name of a feature given\n","    a one-hot vector representing the feature.\n","    \n","    Args:\n","        - onehot: a numpy array one-hot representation of the feature\n","        - feature: a string, should be an element of `catcols`\n","        \n","    Examples:\n","    \n","    >>> get_categorical_value(np.array([0., 0., 0., 0., 0., 1., 0.]), \"work\")\n","    'State-gov'\n","    >>> get_categorical_value(np.array([0.1, 0., 1.1, 0.2, 0., 1., 0.]), \"work\")\n","    'Private'\n","    \"\"\"\n","    return cat_values[feature][np.argmax(onehot)]"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":35},"id":"GvHmVWKEqeTy","executionInfo":{"status":"ok","timestamp":1623460025710,"user_tz":240,"elapsed":137,"user":{"displayName":"Ryan Chen","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiEvvD9_5qPytyzMTOpfMHuCrDH24wjoy50AGq6UQ=s64","userId":"16436951824151695317"}},"outputId":"064dc82f-b6a4-4678-d803-2f6b19d24c4f"},"source":["get_categorical_value(np.array([0., 0., 0., 0., 0., 1., 0.]), \"work\")"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"},"text/plain":["'State-gov'"]},"metadata":{"tags":[]},"execution_count":108}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":35},"id":"giirHCX0qkke","executionInfo":{"status":"ok","timestamp":1623460027477,"user_tz":240,"elapsed":120,"user":{"displayName":"Ryan Chen","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiEvvD9_5qPytyzMTOpfMHuCrDH24wjoy50AGq6UQ=s64","userId":"16436951824151695317"}},"outputId":"6e6b0c0e-2d3f-4df3-ff6b-a3aa99a64b84"},"source":["get_categorical_value(np.array([0.1, 0., 1.1, 0.2, 0., 1., 0.]), \"work\")"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"},"text/plain":["'Private'"]},"metadata":{"tags":[]},"execution_count":109}]},{"cell_type":"code","metadata":{"id":"T_XXxZdh1pqv"},"source":["# more useful code, used during training, that depends on the function\n","# you write above\n","\n","def get_feature(record, feature):\n","    \"\"\"\n","    Return the categorical feature value of a record\n","    \"\"\"\n","    onehot = get_onehot(record, feature)\n","    return get_categorical_value(onehot, feature)\n","\n","def get_features(record):\n","    \"\"\"\n","    Return a dictionary of all categorical feature values of a record\n","    \"\"\"\n","    return { f: get_feature(record, f) for f in catcols }"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"1_5ZZR_J1pqy"},"source":["### Part (g) Train/Test Split [3 pt]\n","\n","Randomly split the data into approximately 70% training, 15% validation and 15% test.\n","\n","Report the number of items in your training, validation, and test set."]},{"cell_type":"code","metadata":{"id":"TE_fTJJf1pqz","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1623460032637,"user_tz":240,"elapsed":114,"user":{"displayName":"Ryan Chen","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiEvvD9_5qPytyzMTOpfMHuCrDH24wjoy50AGq6UQ=s64","userId":"16436951824151695317"}},"outputId":"25a3cdb2-bce5-4293-c1f2-4e5b0bfc8a56"},"source":["# set the numpy seed for reproducibility\n","# https://docs.scipy.org/doc/numpy/reference/generated/numpy.random.seed.html\n","np.random.seed(50)\n","np.random.shuffle(datanp)\n","train_split = int(len(datanp) * 0.7) #split at 70%\n","train_data, val_data = datanp[:train_split], datanp[train_split:]\n","val_split = int(len(val_data) * 0.5)\n","val_data, test_data = val_data[:val_split], val_data[val_split:]\n","\n","print(\"The number of entries in the training set is\", train_data.shape[0])\n","print(\"The number of entries in the validation set is\", val_data.shape[0])\n","print(\"The number of entries in the test set is\", test_data.shape[0])"],"execution_count":null,"outputs":[{"output_type":"stream","text":["The number of entries in the training set is 21502\n","The number of entries in the validation set is 4608\n","The number of entries in the test set is 4608\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"h9wJAKOI1pq3"},"source":["## Part 2. Model Setup [5 pt]\n","\n","### Part (a) [4 pt]\n","\n","Design a fully-connected autoencoder by modifying the `encoder` and `decoder`\n","below.\n","\n","The input to this autoencoder will be the features of the `data`, with\n","one categorical feature recorded as \"missing\". The output of the autoencoder\n","should be the reconstruction of the same features, but with the missing\n","value filled in.\n","\n","**Note**: Do not reduce the dimensionality of the input too much!\n","The output of your embedding is expected to contain information \n","about ~11 features."]},{"cell_type":"code","metadata":{"id":"f3F--tdn1pq3"},"source":["from torch import nn\n","\n","class AutoEncoder(nn.Module):\n","    def __init__(self):\n","        super(AutoEncoder, self).__init__()\n","        self.name = \"autoencoder\"\n","        self.encoder = nn.Sequential(\n","            nn.Linear(57, 30),\n","            nn.ReLU(),\n","            nn.Linear(30, 15)\n","        )\n","        self.decoder = nn.Sequential(\n","            nn.Linear(15, 30),\n","            nn.ReLU(),\n","            nn.Linear(30, 57),\n","            nn.Sigmoid() # get to the range (0, 1)\n","        )\n","\n","    def forward(self, x):\n","        x = self.encoder(x)\n","        x = self.decoder(x)\n","        return x"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"kuEzTSAv1pq6"},"source":["### Part (b) [1 pt]\n","\n","Explain why there is a sigmoid activation in the last step of the decoder.\n","\n","(**Note**: the values inside the data frame `data` and the training code in Part 3 might be helpful.)"]},{"cell_type":"markdown","metadata":{"id":"Amn5a1WHGuij"},"source":["**Answer:**\n","\n","Since the values inside the data frame `data` are all between 0 and 1, the sigmoid activation function is applied to the output layer to scale the output from 0 to 1."]},{"cell_type":"markdown","metadata":{"id":"jYwqFWVl1pq8"},"source":["## Part 3. Training [18] \n","\n","### Part (a) [6 pt]\n","\n","We will train our autoencoder in the following way:\n","\n","- In each iteration, we will hide one of the categorical features using the `zero_out_random_features` function\n","- We will pass the data with one missing feature through the autoencoder, and obtain a reconstruction\n","- We will check how close the reconstruction is compared to the original data -- including the value of the missing feature\n","\n","Complete the code to train the autoencoder, and plot the training and validation loss every few iterations.\n","You may also want to plot training and validation \"accuracy\" every few iterations, as we will define in\n","part (b). You may also want to checkpoint your model every few iterations or epochs.\n","\n","Use `nn.MSELoss()` as your loss function. (Side note: you might recognize that this loss function is not\n","ideal for this problem, but we will use it anyway.)"]},{"cell_type":"code","metadata":{"id":"IDQA_-dS1pq9"},"source":["def zero_out_feature(records, feature):\n","    \"\"\" Set the feature missing in records, by setting the appropriate\n","    columns of records to 0\n","    \"\"\"\n","    start_index = cat_index[feature]\n","    stop_index = cat_index[feature] + len(cat_values[feature])\n","    records[:, start_index:stop_index] = 0\n","    return records\n","\n","def zero_out_random_feature(records):\n","    \"\"\" Set one random feature missing in records, by setting the \n","    appropriate columns of records to 0\n","    \"\"\"\n","    return zero_out_feature(records, random.choice(catcols))\n","\n","def get_model_name(name, learning_rate, epoch):\n","    path = \"model_{0}_lr{1}_epoch{2}\".format(name, learning_rate, epoch)\n","    return path\n","\n","def get_val_loss(model, valid_loader, criterion):\n","    total_val_loss = 0.0\n","    i = 0\n","    for data in train_loader:\n","        datam = zero_out_random_feature(data.clone()) # zero out one categorical feature\n","        recon = model(datam)\n","        loss = criterion(recon, data)\n","        total_val_loss += loss.item()\n","        i += 1\n","    val_loss = float(total_val_loss)/(i + 1)\n","    return val_loss\n","\n","def train(model, train_loader, valid_loader, num_epochs=5, learning_rate=1e-4):\n","    \"\"\" Training loop. You should update this.\"\"\"\n","    torch.manual_seed(42)\n","    criterion = nn.MSELoss()\n","    optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n","\n","    train_acc = np.zeros(num_epochs)\n","    train_loss = np.zeros(num_epochs)\n","    val_acc = np.zeros(num_epochs)\n","    val_loss = np.zeros(num_epochs)\n","\n","    start_time = time.time()\n","    for epoch in range(num_epochs):\n","        total_train_loss = 0.0\n","        i = 0\n","        for data in train_loader:\n","            datam = zero_out_random_feature(data.clone()) # zero out one categorical feature\n","            recon = model(datam)\n","            loss = criterion(recon, data)\n","            loss.backward()\n","            optimizer.step()\n","            optimizer.zero_grad()\n","            total_train_loss += loss.item()\n","            i += 1\n","        train_acc[epoch] = get_accuracy(model, train_loader)\n","        train_loss[epoch] = float(total_train_loss)/(i + 1)\n","        val_acc[epoch] = get_accuracy(model, valid_loader)\n","        val_loss[epoch] = get_val_loss(model, valid_loader, criterion)\n","        print((\"Epoch {}: Train acc: {}, Train loss: {} |\"+\n","               \"Validation acc: {}, Validation loss: {}\").format(\n","                   epoch + 1,\n","                   train_acc[epoch],\n","                   train_loss[epoch],\n","                   val_acc[epoch],\n","                   val_loss[epoch]))\n","        # Save the current model (checkpoint) to a file\n","        model_path = get_model_name(model.name, learning_rate, epoch)\n","        torch.save(model.state_dict(), model_path)\n","    print('Finished Training')\n","    end_time = time.time()\n","    elapsed_time = end_time - start_time\n","    print(\"Total time elapsed: {:.2f} seconds\".format(elapsed_time))\n","\n","    # Plotting\n","    plt.title(\"Train vs Validation Loss\")\n","    plt.plot(range(1 ,num_epochs+1), train_loss, label=\"Train\")\n","    plt.plot(range(1 ,num_epochs+1), val_loss, label=\"Validation\")\n","    plt.xlabel(\"Epochs\")\n","    plt.ylabel(\"Loss\")\n","    plt.legend(loc='best')\n","    plt.show()\n","\n","    plt.title(\"Train vs Validation Accuracy\")\n","    plt.plot(range(1 ,num_epochs+1), train_acc, label=\"Train\")\n","    plt.plot(range(1 ,num_epochs+1), val_acc, label=\"Validation\")\n","    plt.xlabel(\"Epochs\")\n","    plt.ylabel(\"Training Accuracy\")\n","    plt.legend(loc='best')\n","    plt.show()\n","\n","    print(\"Final Training Accuracy: {}\".format(train_acc[-1]))\n","    print(\"Final Validation Accuracy: {}\".format(val_acc[-1]))"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"WKk01pwx1pq_"},"source":["### Part (b) [3 pt]\n","\n","While plotting training and validation loss is valuable, loss values are harder to compare\n","than accuracy percentages. It would be nice to have a measure of \"accuracy\" in this problem.\n","\n","Since we will only be imputing missing categorical values, we will define an accuracy measure.\n","For each record and for each categorical feature, we determine whether\n","the model can predict the categorical feature given all the other features of the record.\n","\n","A function `get_accuracy` is written for you. It is up to you to figure out how to\n","use the function. **You don't need to submit anything in this part.**\n","To earn the marks, correctly plot the training and validation accuracy every few \n","iterations as part of your training curve."]},{"cell_type":"code","metadata":{"id":"bHWLfCzM1pq_"},"source":["def get_accuracy(model, data_loader):\n","    \"\"\"Return the \"accuracy\" of the autoencoder model across a data set.\n","    That is, for each record and for each categorical feature, \n","    we determine whether the model can successfully predict the value\n","    of the categorical feature given all the other features of the \n","    record. The returned \"accuracy\" measure is the percentage of times \n","    that our model is successful.\n","        \n","    Args:\n","       - model: the autoencoder model, an instance of nn.Module\n","       - data_loader: an instance of torch.utils.data.DataLoader\n","\n","    Example (to illustrate how get_accuracy is intended to be called.\n","             Depending on your variable naming this code might require\n","             modification.)\n","\n","        >>> model = AutoEncoder()\n","        >>> vdl = torch.utils.data.DataLoader(data_valid, batch_size=256, shuffle=True)\n","        >>> get_accuracy(model, vdl)\n","    \"\"\"\n","    total = 0\n","    acc = 0\n","    for col in catcols:\n","        for item in data_loader: # minibatches\n","            inp = item.detach().numpy()\n","            out = model(zero_out_feature(item.clone(), col)).detach().numpy()\n","            for i in range(out.shape[0]): # record in minibatch\n","                acc += int(get_feature(out[i], col) == get_feature(inp[i], col))\n","                total += 1\n","    return acc / total"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"SxCTlXoV1prB"},"source":["### Part (c) [4 pt]\n","\n","Run your updated training code, using reasonable initial hyperparameters.\n","\n","Include your training curve in your submission."]},{"cell_type":"code","metadata":{"id":"nj5b71l-1prC","colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"status":"ok","timestamp":1623446828275,"user_tz":240,"elapsed":95788,"user":{"displayName":"Ryan Chen","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiEvvD9_5qPytyzMTOpfMHuCrDH24wjoy50AGq6UQ=s64","userId":"16436951824151695317"}},"outputId":"ea07f0e8-3233-446b-ec68-f78acbf92c65"},"source":["train_loader = torch.utils.data.DataLoader(train_data, batch_size=64, shuffle=True)\n","valid_loader = torch.utils.data.DataLoader(val_data, batch_size=64, shuffle=True)\n","model = AutoEncoder()\n","train(model, train_loader, valid_loader, num_epochs=30)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Epoch 1: Train acc: 0.38208073667565806, Train loss: 0.20862779812749133 |Validation acc: 0.3844401041666667, Validation loss: 0.1374495572435396\n","Epoch 2: Train acc: 0.45940687687967013, Train loss: 0.08729150771917858 |Validation acc: 0.4583333333333333, Validation loss: 0.07259809625962367\n","Epoch 3: Train acc: 0.4596781694726072, Train loss: 0.07142292164288218 |Validation acc: 0.45829716435185186, Validation loss: 0.07073208499556126\n","Epoch 4: Train acc: 0.4588487892599138, Train loss: 0.0703882221298331 |Validation acc: 0.4575737847222222, Validation loss: 0.07007463002240269\n","Epoch 5: Train acc: 0.45833720894180385, Train loss: 0.06974058709928119 |Validation acc: 0.45703125, Validation loss: 0.06936035490973413\n","Epoch 6: Train acc: 0.45749232629522835, Train loss: 0.06884427061332085 |Validation acc: 0.4564525462962963, Validation loss: 0.06809887365169978\n","Epoch 7: Train acc: 0.47432796949121014, Train loss: 0.0666355416289246 |Validation acc: 0.4722945601851852, Validation loss: 0.0646185653079688\n","Epoch 8: Train acc: 0.516998418751744, Train loss: 0.061786324128464354 |Validation acc: 0.5159866898148148, Validation loss: 0.05902343006799058\n","Epoch 9: Train acc: 0.525423991566676, Train loss: 0.05730416851245331 |Validation acc: 0.5253544560185185, Validation loss: 0.05590584302647177\n","Epoch 10: Train acc: 0.5350975103091186, Train loss: 0.05517897751591326 |Validation acc: 0.5360604745370371, Validation loss: 0.05459686182992041\n","Epoch 11: Train acc: 0.5480342913837473, Train loss: 0.05403128961648361 |Validation acc: 0.5491898148148148, Validation loss: 0.05364152264037896\n","Epoch 12: Train acc: 0.5581418782748891, Train loss: 0.05309944977923034 |Validation acc: 0.5600405092592593, Validation loss: 0.052431881328276427\n","Epoch 13: Train acc: 0.561870213623539, Train loss: 0.05191222589341399 |Validation acc: 0.5613064236111112, Validation loss: 0.05103880689874601\n","Epoch 14: Train acc: 0.5684354943726165, Train loss: 0.05007020992058321 |Validation acc: 0.5684317129629629, Validation loss: 0.04920812065019452\n","Epoch 15: Train acc: 0.577450159675069, Train loss: 0.048046773481970374 |Validation acc: 0.5770399305555556, Validation loss: 0.04686735155895485\n","Epoch 16: Train acc: 0.5738613462313583, Train loss: 0.045652775950619305 |Validation acc: 0.5738932291666666, Validation loss: 0.04458768722167355\n","Epoch 17: Train acc: 0.5785430812637584, Train loss: 0.04365983642969358 |Validation acc: 0.5787760416666666, Validation loss: 0.042735877339051105\n","Epoch 18: Train acc: 0.5785740861315226, Train loss: 0.041951423505381946 |Validation acc: 0.5786313657407407, Validation loss: 0.041136742345657125\n","Epoch 19: Train acc: 0.5808529439121942, Train loss: 0.04027368076344626 |Validation acc: 0.5819227430555556, Validation loss: 0.039731567509980865\n","Epoch 20: Train acc: 0.5819536167178248, Train loss: 0.03917394729900431 |Validation acc: 0.5828269675925926, Validation loss: 0.03851173579339104\n","Epoch 21: Train acc: 0.5833178308994512, Train loss: 0.038091417855254266 |Validation acc: 0.5845269097222222, Validation loss: 0.03745902534187371\n","Epoch 22: Train acc: 0.5852866400024804, Train loss: 0.03733723253586526 |Validation acc: 0.5882884837962963, Validation loss: 0.03667053050231686\n","Epoch 23: Train acc: 0.5874802343968003, Train loss: 0.03644546204818639 |Validation acc: 0.5901331018518519, Validation loss: 0.03604809307556831\n","Epoch 24: Train acc: 0.593022354509658, Train loss: 0.03565637931470878 |Validation acc: 0.5937861689814815, Validation loss: 0.03535149658225941\n","Epoch 25: Train acc: 0.5956577682696184, Train loss: 0.034933784213856706 |Validation acc: 0.5963903356481481, Validation loss: 0.03456755483230073\n","Epoch 26: Train acc: 0.5980994016060521, Train loss: 0.03432839913763526 |Validation acc: 0.5978009259259259, Validation loss: 0.033998312461756455\n","Epoch 27: Train acc: 0.5998434254177906, Train loss: 0.03353790844892889 |Validation acc: 0.59765625, Validation loss: 0.03314605205477345\n","Epoch 28: Train acc: 0.6011378786469476, Train loss: 0.03288430454712416 |Validation acc: 0.6000434027777778, Validation loss: 0.032791547344594045\n","Epoch 29: Train acc: 0.602486590394692, Train loss: 0.0323814817590954 |Validation acc: 0.5998987268518519, Validation loss: 0.031933274529100525\n","Epoch 30: Train acc: 0.6038585557932595, Train loss: 0.0316823019538329 |Validation acc: 0.6009114583333334, Validation loss: 0.03148753964825801\n","Finished Training\n","Total time elapsed: 95.35 seconds\n"],"name":"stdout"},{"output_type":"display_data","data":{"image/png":"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\n","text/plain":["<Figure size 432x288 with 1 Axes>"]},"metadata":{"tags":[],"needs_background":"light"}},{"output_type":"display_data","data":{"image/png":"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\n","text/plain":["<Figure size 432x288 with 1 Axes>"]},"metadata":{"tags":[],"needs_background":"light"}},{"output_type":"stream","text":["Final Training Accuracy: 0.6038585557932595\n","Final Validation Accuracy: 0.6009114583333334\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"h9xTwIf51prF"},"source":["### Part (d) [5 pt]\n","\n","Tune your hyperparameters, training at least 4 different models (4 sets of hyperparameters).\n","\n","Do not include all your training curves. Instead, explain what hyperparameters\n","you tried, what their effect was, and what your thought process was as you \n","chose the next set of hyperparameters to try."]},{"cell_type":"code","metadata":{"id":"PhTKt9iL1prG"},"source":["# Since the training accuracy of the model in Part (c) was still increasing near the end, num_epochs is increased from 30 to 150\n","train_loader = torch.utils.data.DataLoader(train_data, batch_size=64, shuffle=True)\n","valid_loader = torch.utils.data.DataLoader(val_data, batch_size=64, shuffle=True)\n","model_1 = AutoEncoder()\n","train(model_1, train_loader, valid_loader, num_epochs=150)\n","\n","# Results:\n","# Increasing num_epochs increased the training and validation accuracies\n","# Final Training Accuracy: 0.6297321179425169\n","# Final Validation Accuracy: 0.6265552662037037"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"f8u5v_TgBZR0"},"source":["# Since the training accuracy of model_1 still seems to increase near the end, num_epochs is increased from 150 to 300\n","train_loader = torch.utils.data.DataLoader(train_data, batch_size=64, shuffle=True)\n","valid_loader = torch.utils.data.DataLoader(val_data, batch_size=64, shuffle=True)\n","model_2 = AutoEncoder()\n","train(model_2, train_loader, valid_loader, num_epochs=300)\n","\n","# Results:\n","# Increasing num_epochs increased the training and validation accuracies\n","# Final Training Accuracy: 0.6311195857749666\n","# Final Validation Accuracy: 0.6269169560185185"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"idcEpIKsF5Qd"},"source":["# Since the previous two models were trained at a very slow rate, learning_rate is increased from 1e-4 to 5e-4\n","train_loader = torch.utils.data.DataLoader(train_data, batch_size=64, shuffle=True)\n","valid_loader = torch.utils.data.DataLoader(val_data, batch_size=64, shuffle=True)\n","model_3 = AutoEncoder()\n","train(model_3, train_loader, valid_loader, num_epochs=300, learning_rate=5e-4)\n","\n","# Results:\n","# Increasing learning_rate increased the training and validation accuracies, but it also made the training curves\n","# more noisy with more fluctuations. \n","# Final Training Accuracy: 0.6833007782221809\n","# Final Validation Accuracy: 0.6796151620370371"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"ezllOn8UMJuX"},"source":["# Since increasing the learning_rate significantly improved the training and validation accuracies, \n","# learning_rate is further increased from 5e-4 to 0.00075 so the model can learn even faster\n","train_loader = torch.utils.data.DataLoader(train_data, batch_size=64, shuffle=True)\n","valid_loader = torch.utils.data.DataLoader(val_data, batch_size=64, shuffle=True)\n","model_4 = AutoEncoder()\n","train(model_4, train_loader, valid_loader, num_epochs=300, learning_rate=0.00075)\n","\n","# Results:\n","# Increasing learning_rate increased the training and validation accuracies, but it also made the training curves\n","# even more noisy with more fluctuations compared to model_3. \n","# Final Training Accuracy: 0.6957182277617586\n","# Final Validation Accuracy: 0.6915509259259259"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"id":"T8LXUsuTRRNe","executionInfo":{"status":"ok","timestamp":1623456102395,"user_tz":240,"elapsed":1947677,"user":{"displayName":"Ryan Chen","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiEvvD9_5qPytyzMTOpfMHuCrDH24wjoy50AGq6UQ=s64","userId":"16436951824151695317"}},"outputId":"26bf1242-df77-459a-ade8-408784c12292"},"source":["# Since the training curves are starting to become more and more noisy due to the increase in\n","# learning_rate, it will not be further increased. However, training accuracy of model_4 still \n","# seems to increase near the end, so num_epochs is increased from 300 to 600\n","train_loader = torch.utils.data.DataLoader(train_data, batch_size=64, shuffle=True)\n","valid_loader = torch.utils.data.DataLoader(val_data, batch_size=64, shuffle=True)\n","model_5 = AutoEncoder()\n","train(model_5, train_loader, valid_loader, num_epochs=600, learning_rate=0.00075)\n","\n","# Results:\n","# This set of hyperparameters produces the best learned model\n","# Final Training Accuracy: 0.7151427774160544\n","# Final Validation Accuracy: 0.7076099537037037"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Epoch 1: Train acc: 0.5309816141134158, Train loss: 0.09496343219846222 |Validation acc: 0.5297309027777778, Validation loss: 0.055621624910424654\n","Epoch 2: Train acc: 0.5799460515300903, Train loss: 0.05101048515263934 |Validation acc: 0.5782696759259259, Validation loss: 0.04634870735801292\n","Epoch 3: Train acc: 0.5998434254177906, Train loss: 0.04141154051799802 |Validation acc: 0.5967520254629629, Validation loss: 0.0373355060848974\n","Epoch 4: Train acc: 0.6134468111493504, Train loss: 0.03475015092563735 |Validation acc: 0.6093026620370371, Validation loss: 0.03262321443714268\n","Epoch 5: Train acc: 0.6129739869159458, Train loss: 0.031112549351169024 |Validation acc: 0.6084346064814815, Validation loss: 0.029488086015074473\n","Epoch 6: Train acc: 0.6100285244783431, Train loss: 0.028163398049484374 |Validation acc: 0.6053602430555556, Validation loss: 0.02715853609432099\n","Epoch 7: Train acc: 0.6107571388708027, Train loss: 0.025897714798545978 |Validation acc: 0.6090133101851852, Validation loss: 0.024493559078487517\n","Epoch 8: Train acc: 0.611695036120671, Train loss: 0.023902389903494796 |Validation acc: 0.6085069444444444, Validation loss: 0.02297352886142469\n","Epoch 9: Train acc: 0.614415713266983, Train loss: 0.02256955552669325 |Validation acc: 0.6119068287037037, Validation loss: 0.021935903215753217\n","Epoch 10: Train acc: 0.6227870275633275, Train loss: 0.02176760871637646 |Validation acc: 0.6203703703703703, Validation loss: 0.021333424681217274\n","Epoch 11: Train acc: 0.6162915077667194, Train loss: 0.02104854257086441 |Validation acc: 0.6108579282407407, Validation loss: 0.020768934764100643\n","Epoch 12: Train acc: 0.6243837782531857, Train loss: 0.02057666969913934 |Validation acc: 0.6201895254629629, Validation loss: 0.019839456766423732\n","Epoch 13: Train acc: 0.623515641955787, Train loss: 0.019612456262885464 |Validation acc: 0.6177662037037037, Validation loss: 0.01917563683079771\n","Epoch 14: Train acc: 0.6277478064056057, Train loss: 0.019007412946122515 |Validation acc: 0.6253978587962963, Validation loss: 0.018658459252879598\n","Epoch 15: Train acc: 0.6267246457693858, Train loss: 0.018425075674446116 |Validation acc: 0.6220341435185185, Validation loss: 0.01784237236536221\n","Epoch 16: Train acc: 0.6271509627011441, Train loss: 0.018083317318616177 |Validation acc: 0.6213831018518519, Validation loss: 0.017786949049427177\n","Epoch 17: Train acc: 0.6272439773044368, Train loss: 0.01761365145478033 |Validation acc: 0.6189959490740741, Validation loss: 0.01712106692795407\n","Epoch 18: Train acc: 0.6344681114935045, Train loss: 0.016729918576622222 |Validation acc: 0.6270254629629629, Validation loss: 0.016685595970810874\n","Epoch 19: Train acc: 0.6302436982606269, Train loss: 0.01659342707950036 |Validation acc: 0.6231553819444444, Validation loss: 0.016227395613663983\n","Epoch 20: Train acc: 0.6308017858803833, Train loss: 0.01617400275504642 |Validation acc: 0.6247106481481481, Validation loss: 0.015797270660893852\n","Epoch 21: Train acc: 0.6312048491613184, Train loss: 0.015907581906644104 |Validation acc: 0.6257595486111112, Validation loss: 0.015886073885070996\n","Epoch 22: Train acc: 0.6338170092704555, Train loss: 0.015384846389050476 |Validation acc: 0.6276765046296297, Validation loss: 0.015430769838879123\n","Epoch 23: Train acc: 0.6308637956159117, Train loss: 0.01508915513472007 |Validation acc: 0.6243489583333334, Validation loss: 0.015383969829348676\n","Epoch 24: Train acc: 0.6347471553033827, Train loss: 0.015098830850833602 |Validation acc: 0.6282913773148148, Validation loss: 0.015387267670221074\n","Epoch 25: Train acc: 0.6399249682200105, Train loss: 0.015119063557410276 |Validation acc: 0.6337167245370371, Validation loss: 0.014592083766559023\n","Epoch 26: Train acc: 0.6388475490652032, Train loss: 0.014761345427848111 |Validation acc: 0.6331380208333334, Validation loss: 0.014710551889154518\n","Epoch 27: Train acc: 0.6410566458934053, Train loss: 0.014797429883029057 |Validation acc: 0.6368272569444444, Validation loss: 0.014106971713319112\n","Epoch 28: Train acc: 0.6415914798623383, Train loss: 0.013995484755725464 |Validation acc: 0.6354528356481481, Validation loss: 0.014168128391965473\n","Epoch 29: Train acc: 0.6394909000713112, Train loss: 0.014105835269020112 |Validation acc: 0.6334635416666666, Validation loss: 0.014032459804008905\n","Epoch 30: Train acc: 0.6391963538275509, Train loss: 0.013901810666120637 |Validation acc: 0.6334997106481481, Validation loss: 0.013675414074145987\n","Epoch 31: Train acc: 0.6391498465259046, Train loss: 0.013900610923667601 |Validation acc: 0.6329210069444444, Validation loss: 0.013767591464811334\n","Epoch 32: Train acc: 0.6380259200694509, Train loss: 0.013690488146291908 |Validation acc: 0.6325593171296297, Validation loss: 0.013793715925262661\n","Epoch 33: Train acc: 0.6395761634576629, Train loss: 0.013445496955715142 |Validation acc: 0.6323061342592593, Validation loss: 0.013235098298207942\n","Epoch 34: Train acc: 0.6413279384863424, Train loss: 0.013368393265495757 |Validation acc: 0.6356698495370371, Validation loss: 0.013413160258644323\n","Epoch 35: Train acc: 0.6422348308684463, Train loss: 0.01335069065836178 |Validation acc: 0.6362485532407407, Validation loss: 0.013248763316606644\n","Epoch 36: Train acc: 0.6416147335131616, Train loss: 0.013114999596980188 |Validation acc: 0.6365017361111112, Validation loss: 0.013253296713015889\n","Epoch 37: Train acc: 0.6408241093851734, Train loss: 0.013128362264406787 |Validation acc: 0.6346209490740741, Validation loss: 0.012767125665865154\n","Epoch 38: Train acc: 0.6449322543639351, Train loss: 0.013304881703174875 |Validation acc: 0.6397207754629629, Validation loss: 0.012841789719292158\n","Epoch 39: Train acc: 0.6391653489597867, Train loss: 0.013057169367667033 |Validation acc: 0.6344039351851852, Validation loss: 0.01305564308334529\n","Epoch 40: Train acc: 0.6423123430378569, Train loss: 0.012819482520697997 |Validation acc: 0.6377676504629629, Validation loss: 0.013146825065664969\n","Epoch 41: Train acc: 0.6472653706631941, Train loss: 0.013004667533268649 |Validation acc: 0.6415292245370371, Validation loss: 0.013060201882475916\n","Epoch 42: Train acc: 0.6473506340495457, Train loss: 0.012874107813401817 |Validation acc: 0.640625, Validation loss: 0.012829759369607053\n","Epoch 43: Train acc: 0.6466297708740272, Train loss: 0.012762113287768573 |Validation acc: 0.6415292245370371, Validation loss: 0.012967459498199935\n","Epoch 44: Train acc: 0.6446609617709981, Train loss: 0.012500098918893482 |Validation acc: 0.6389612268518519, Validation loss: 0.012532798259709727\n","Epoch 45: Train acc: 0.6485133165907048, Train loss: 0.012366675482979957 |Validation acc: 0.6420717592592593, Validation loss: 0.012540450862688993\n","Epoch 46: Train acc: 0.6458158930952159, Train loss: 0.012203120822722551 |Validation acc: 0.6405164930555556, Validation loss: 0.012574433940476587\n","Epoch 47: Train acc: 0.6482807800824729, Train loss: 0.012390315532684326 |Validation acc: 0.6423972800925926, Validation loss: 0.012921470431583306\n","Epoch 48: Train acc: 0.6525206957492327, Train loss: 0.012338390513060708 |Validation acc: 0.6464482060185185, Validation loss: 0.012566418023586538\n","Epoch 49: Train acc: 0.6515052863299537, Train loss: 0.012361503076305728 |Validation acc: 0.6461950231481481, Validation loss: 0.012346644251599068\n","Epoch 50: Train acc: 0.6513270083403094, Train loss: 0.012289697927552709 |Validation acc: 0.6447844328703703, Validation loss: 0.012281576765684593\n","Epoch 51: Train acc: 0.6437695718227762, Train loss: 0.012673492420420537 |Validation acc: 0.6367549189814815, Validation loss: 0.012755094708194983\n","Epoch 52: Train acc: 0.6491179115121074, Train loss: 0.01237554738480454 |Validation acc: 0.6424334490740741, Validation loss: 0.012133593063038782\n","Epoch 53: Train acc: 0.648807862834465, Train loss: 0.012191568911683577 |Validation acc: 0.6431929976851852, Validation loss: 0.012001043558673442\n","Epoch 54: Train acc: 0.6533113198772207, Train loss: 0.012483162976779287 |Validation acc: 0.6476779513888888, Validation loss: 0.012001129299767028\n","Epoch 55: Train acc: 0.6507844231544353, Train loss: 0.012545109488821702 |Validation acc: 0.6459056712962963, Validation loss: 0.012505300746517648\n","Epoch 56: Train acc: 0.6548770656993148, Train loss: 0.012091659564933898 |Validation acc: 0.6471715856481481, Validation loss: 0.01216996735713558\n","Epoch 57: Train acc: 0.6514665302452485, Train loss: 0.012214930629971208 |Validation acc: 0.6453631365740741, Validation loss: 0.012149226531187399\n","Epoch 58: Train acc: 0.6527377298235824, Train loss: 0.012079597283596897 |Validation acc: 0.6458333333333334, Validation loss: 0.012144526893698585\n","Epoch 59: Train acc: 0.6522106470715903, Train loss: 0.012275310434975857 |Validation acc: 0.6469184027777778, Validation loss: 0.01196321103036492\n","Epoch 60: Train acc: 0.6525284469661737, Train loss: 0.012306465935901647 |Validation acc: 0.6470992476851852, Validation loss: 0.01210632160836582\n","Epoch 61: Train acc: 0.65089294019161, Train loss: 0.011635144552055646 |Validation acc: 0.6452546296296297, Validation loss: 0.011964260168008794\n","Epoch 62: Train acc: 0.6536833782903916, Train loss: 0.011935401069503334 |Validation acc: 0.6477141203703703, Validation loss: 0.011942367027969672\n","Epoch 63: Train acc: 0.6517300716212445, Train loss: 0.011890787292736132 |Validation acc: 0.6450014467592593, Validation loss: 0.011876699398617185\n","Epoch 64: Train acc: 0.6544584999844976, Train loss: 0.0120757882986273 |Validation acc: 0.6489438657407407, Validation loss: 0.011833555783623228\n","Epoch 65: Train acc: 0.6559777385049452, Train loss: 0.011706073490698278 |Validation acc: 0.6494502314814815, Validation loss: 0.012150479922795155\n","Epoch 66: Train acc: 0.654388739032028, Train loss: 0.011841084097874094 |Validation acc: 0.6491608796296297, Validation loss: 0.01192004394438394\n","Epoch 67: Train acc: 0.6520168666480638, Train loss: 0.0122171903626015 |Validation acc: 0.6452184606481481, Validation loss: 0.012103708788409873\n","Epoch 68: Train acc: 0.6573884599882182, Train loss: 0.012024033865794672 |Validation acc: 0.6530309606481481, Validation loss: 0.01195804419504473\n","Epoch 69: Train acc: 0.6549700803026075, Train loss: 0.012078400789718599 |Validation acc: 0.6490162037037037, Validation loss: 0.012157839989615742\n","Epoch 70: Train acc: 0.6544584999844976, Train loss: 0.011874735580608028 |Validation acc: 0.6494140625, Validation loss: 0.01224815835402477\n","Epoch 71: Train acc: 0.6553653923666015, Train loss: 0.01173395703571575 |Validation acc: 0.6503182870370371, Validation loss: 0.011474799945154601\n","Epoch 72: Train acc: 0.651528539980777, Train loss: 0.011486409755716603 |Validation acc: 0.6456524884259259, Validation loss: 0.011947925958384481\n","Epoch 73: Train acc: 0.6539314172325055, Train loss: 0.011439336271741004 |Validation acc: 0.6474609375, Validation loss: 0.011584768106315273\n","Epoch 74: Train acc: 0.6538384026292128, Train loss: 0.011985038542561785 |Validation acc: 0.6485098379629629, Validation loss: 0.011551351174546367\n","Epoch 75: Train acc: 0.6516448082348929, Train loss: 0.011526895012673356 |Validation acc: 0.6467375578703703, Validation loss: 0.011790262973240026\n","Epoch 76: Train acc: 0.6576597525811553, Train loss: 0.01159946178431548 |Validation acc: 0.6511501736111112, Validation loss: 0.011469341241077517\n","Epoch 77: Train acc: 0.6523269153257061, Train loss: 0.011595836453670388 |Validation acc: 0.6471354166666666, Validation loss: 0.011815673468540525\n","Epoch 78: Train acc: 0.6576054940625679, Train loss: 0.011815025059379173 |Validation acc: 0.6505353009259259, Validation loss: 0.011329469588814573\n","Epoch 79: Train acc: 0.6530632809351068, Train loss: 0.011630357483551127 |Validation acc: 0.6481481481481481, Validation loss: 0.011740647992865356\n","Epoch 80: Train acc: 0.6577450159675069, Train loss: 0.011660437942523985 |Validation acc: 0.6513310185185185, Validation loss: 0.011407571470293075\n","Epoch 81: Train acc: 0.6521951446377081, Train loss: 0.011912781213208459 |Validation acc: 0.6469545717592593, Validation loss: 0.011397102963765227\n","Epoch 82: Train acc: 0.6588379375561964, Train loss: 0.011631625620178459 |Validation acc: 0.6549117476851852, Validation loss: 0.01169117163446696\n","Epoch 83: Train acc: 0.6592332496201904, Train loss: 0.011387417544762794 |Validation acc: 0.6553819444444444, Validation loss: 0.01144216137659081\n","Epoch 84: Train acc: 0.6604966979815831, Train loss: 0.011566253674689138 |Validation acc: 0.6548755787037037, Validation loss: 0.011352437723825964\n","Epoch 85: Train acc: 0.6610702880352215, Train loss: 0.011623466898651258 |Validation acc: 0.6554904513888888, Validation loss: 0.011673690404367111\n","Epoch 86: Train acc: 0.6612485660248659, Train loss: 0.01162720992415038 |Validation acc: 0.6545500578703703, Validation loss: 0.011360688577198842\n","Epoch 87: Train acc: 0.6622794778780269, Train loss: 0.011392747625454332 |Validation acc: 0.6562138310185185, Validation loss: 0.011242817840000023\n","Epoch 88: Train acc: 0.6569466406225778, Train loss: 0.011398826787961254 |Validation acc: 0.6519097222222222, Validation loss: 0.011167206504390483\n","Epoch 89: Train acc: 0.6629073264502527, Train loss: 0.011545479104188147 |Validation acc: 0.6581307870370371, Validation loss: 0.011268529638880172\n","Epoch 90: Train acc: 0.6589774594611354, Train loss: 0.01131169263892517 |Validation acc: 0.6531394675925926, Validation loss: 0.011233286565937963\n","Epoch 91: Train acc: 0.6588999472917249, Train loss: 0.011338972041621053 |Validation acc: 0.6528501157407407, Validation loss: 0.011289247527210047\n","Epoch 92: Train acc: 0.6657287694167985, Train loss: 0.011222711645442583 |Validation acc: 0.6602647569444444, Validation loss: 0.011048353943166818\n","Epoch 93: Train acc: 0.6579775524757386, Train loss: 0.011615836926534197 |Validation acc: 0.6541883680555556, Validation loss: 0.011273739902297096\n","Epoch 94: Train acc: 0.6666201593650203, Train loss: 0.011180925913962041 |Validation acc: 0.6616030092592593, Validation loss: 0.011332705267359577\n","Epoch 95: Train acc: 0.6635816823241248, Train loss: 0.011310827474797957 |Validation acc: 0.65625, Validation loss: 0.011278096341890026\n","Epoch 96: Train acc: 0.6659923107927944, Train loss: 0.01118545603277908 |Validation acc: 0.6598668981481481, Validation loss: 0.011205519452823729\n","Epoch 97: Train acc: 0.6649613989396336, Train loss: 0.011012764239976686 |Validation acc: 0.6595052083333334, Validation loss: 0.01145361118897442\n","Epoch 98: Train acc: 0.6651784330139832, Train loss: 0.011097410996375434 |Validation acc: 0.66015625, Validation loss: 0.010998703785329085\n","Epoch 99: Train acc: 0.6611012929029858, Train loss: 0.011119009006646868 |Validation acc: 0.6561053240740741, Validation loss: 0.010635232156313934\n","Epoch 100: Train acc: 0.6635429262394196, Train loss: 0.011061536743739504 |Validation acc: 0.6584924768518519, Validation loss: 0.010940944496818572\n","Epoch 101: Train acc: 0.661651629305801, Train loss: 0.010782694010870968 |Validation acc: 0.6567563657407407, Validation loss: 0.010931896088639335\n","Epoch 102: Train acc: 0.6599231079279447, Train loss: 0.010871997817477504 |Validation acc: 0.6536820023148148, Validation loss: 0.011005403473973274\n","Epoch 103: Train acc: 0.6624577558676712, Train loss: 0.011122594848662085 |Validation acc: 0.6580946180555556, Validation loss: 0.011234800328530968\n","Epoch 104: Train acc: 0.6696121291042694, Train loss: 0.01091994625828519 |Validation acc: 0.6649667245370371, Validation loss: 0.010880861881821906\n","Epoch 105: Train acc: 0.6687982513254581, Train loss: 0.010971644937505708 |Validation acc: 0.6631944444444444, Validation loss: 0.010939950011504775\n","Epoch 106: Train acc: 0.6631243605246023, Train loss: 0.010830018630676877 |Validation acc: 0.6595775462962963, Validation loss: 0.01077810318958158\n","Epoch 107: Train acc: 0.6703252410628469, Train loss: 0.010895160945734833 |Validation acc: 0.6644603587962963, Validation loss: 0.011119479032990575\n","Epoch 108: Train acc: 0.6677285833875919, Train loss: 0.010900803805724096 |Validation acc: 0.6635561342592593, Validation loss: 0.010665188999487313\n","Epoch 109: Train acc: 0.6652559451833938, Train loss: 0.010885077304806482 |Validation acc: 0.6607711226851852, Validation loss: 0.010848239290829228\n","Epoch 110: Train acc: 0.671774718630825, Train loss: 0.011039842348490519 |Validation acc: 0.6671368634259259, Validation loss: 0.010754027676102581\n","Epoch 111: Train acc: 0.6732164449818622, Train loss: 0.010531396701799303 |Validation acc: 0.6694155092592593, Validation loss: 0.010553690915767003\n","Epoch 112: Train acc: 0.6636979505782408, Train loss: 0.010823107238869992 |Validation acc: 0.6606626157407407, Validation loss: 0.010810750200156156\n","Epoch 113: Train acc: 0.6700461972529688, Train loss: 0.010770439758941045 |Validation acc: 0.6663049768518519, Validation loss: 0.010915886341298458\n","Epoch 114: Train acc: 0.6698136607447369, Train loss: 0.010701525671744736 |Validation acc: 0.6648220486111112, Validation loss: 0.011143943308700617\n","Epoch 115: Train acc: 0.66749604687936, Train loss: 0.010574539095295996 |Validation acc: 0.6629774305555556, Validation loss: 0.010540712150836292\n","Epoch 116: Train acc: 0.6750922394815986, Train loss: 0.010725875177837975 |Validation acc: 0.6683666087962963, Validation loss: 0.010469455274722874\n","Epoch 117: Train acc: 0.6718522308002356, Train loss: 0.010815537121500653 |Validation acc: 0.6678240740740741, Validation loss: 0.010442879873131698\n","Epoch 118: Train acc: 0.6695423681517998, Train loss: 0.010403837573380162 |Validation acc: 0.6622178819444444, Validation loss: 0.01053342500629694\n","Epoch 119: Train acc: 0.680990915573745, Train loss: 0.010582950811844197 |Validation acc: 0.6762876157407407, Validation loss: 0.010509603169058569\n","Epoch 120: Train acc: 0.6745961615973708, Train loss: 0.010531943214045788 |Validation acc: 0.6696686921296297, Validation loss: 0.010309819245395922\n","Epoch 121: Train acc: 0.6712321334449508, Train loss: 0.010610246103677003 |Validation acc: 0.6657986111111112, Validation loss: 0.010394537878065241\n","Epoch 122: Train acc: 0.6801382817102285, Train loss: 0.010249323344261603 |Validation acc: 0.6740089699074074, Validation loss: 0.010515938167534879\n","Epoch 123: Train acc: 0.6714414163023594, Train loss: 0.010241578689580148 |Validation acc: 0.6666304976851852, Validation loss: 0.010321024157250582\n","Epoch 124: Train acc: 0.6767742535578086, Train loss: 0.010354181997566443 |Validation acc: 0.6712962962962963, Validation loss: 0.010727318135043191\n","Epoch 125: Train acc: 0.6786345456236629, Train loss: 0.010886685777654545 |Validation acc: 0.6737919560185185, Validation loss: 0.01053187450620647\n","Epoch 126: Train acc: 0.6707593092115463, Train loss: 0.010393489558437635 |Validation acc: 0.6665943287037037, Validation loss: 0.010535184936515037\n","Epoch 127: Train acc: 0.6799289988528199, Train loss: 0.010356908445785414 |Validation acc: 0.6753110532407407, Validation loss: 0.010128721773060652\n","Epoch 128: Train acc: 0.6854556165317955, Train loss: 0.010347546197098158 |Validation acc: 0.6804470486111112, Validation loss: 0.01045056593187087\n","Epoch 129: Train acc: 0.6826961833007782, Train loss: 0.010235866050868785 |Validation acc: 0.6781322337962963, Validation loss: 0.01030935602295779\n","Epoch 130: Train acc: 0.6788903357827178, Train loss: 0.010764591066990303 |Validation acc: 0.6744791666666666, Validation loss: 0.010244427346942244\n","Epoch 131: Train acc: 0.687990264471522, Train loss: 0.010300726433580282 |Validation acc: 0.6839916087962963, Validation loss: 0.010073063142033907\n","Epoch 132: Train acc: 0.6807738814993954, Train loss: 0.010625220592014867 |Validation acc: 0.6761429398148148, Validation loss: 0.010419460729963923\n","Epoch 133: Train acc: 0.6814559885902086, Train loss: 0.010292360332493259 |Validation acc: 0.6773003472222222, Validation loss: 0.009856569605605893\n","Epoch 134: Train acc: 0.67254208910799, Train loss: 0.010196952091237027 |Validation acc: 0.6671368634259259, Validation loss: 0.010422742844059047\n","Epoch 135: Train acc: 0.6851378166372121, Train loss: 0.010539948990021333 |Validation acc: 0.6794343171296297, Validation loss: 0.010532646654146096\n","Epoch 136: Train acc: 0.685393606796267, Train loss: 0.010140961082375855 |Validation acc: 0.6826895254629629, Validation loss: 0.010333116124840095\n","Epoch 137: Train acc: 0.6771850680556848, Train loss: 0.010097512739050017 |Validation acc: 0.6711154513888888, Validation loss: 0.010243059343241089\n","Epoch 138: Train acc: 0.6859439431990823, Train loss: 0.010279225712664182 |Validation acc: 0.6810619212962963, Validation loss: 0.010085307160469783\n","Epoch 139: Train acc: 0.6772935850928595, Train loss: 0.010064292688735205 |Validation acc: 0.6713686342592593, Validation loss: 0.010319640468916572\n","Epoch 140: Train acc: 0.6820528322946703, Train loss: 0.010206375750561054 |Validation acc: 0.6774811921296297, Validation loss: 0.01013607374815276\n","Epoch 141: Train acc: 0.6838821194927603, Train loss: 0.010081820824191814 |Validation acc: 0.6783130787037037, Validation loss: 0.01025675669953625\n","Epoch 142: Train acc: 0.6847890118748644, Train loss: 0.01001845526810216 |Validation acc: 0.6802300347222222, Validation loss: 0.010392757244573945\n","Epoch 143: Train acc: 0.6877112206616439, Train loss: 0.010290772956726901 |Validation acc: 0.681640625, Validation loss: 0.010206846071224804\n","Epoch 144: Train acc: 0.6894397420395002, Train loss: 0.010376607779501897 |Validation acc: 0.6836299189814815, Validation loss: 0.009941006113860744\n","Epoch 145: Train acc: 0.6878894986512882, Train loss: 0.010181158403824539 |Validation acc: 0.6823640046296297, Validation loss: 0.010333502374987397\n","Epoch 146: Train acc: 0.6926177409853347, Train loss: 0.010126122390956394 |Validation acc: 0.6882233796296297, Validation loss: 0.009947388589061598\n","Epoch 147: Train acc: 0.6907264440517161, Train loss: 0.010055992703951166 |Validation acc: 0.6851851851851852, Validation loss: 0.010076280552009535\n","Epoch 148: Train acc: 0.6910674975971227, Train loss: 0.010146782806734568 |Validation acc: 0.6855107060185185, Validation loss: 0.009728575009266771\n","Epoch 149: Train acc: 0.6879825132545809, Train loss: 0.010024964320266106 |Validation acc: 0.6831235532407407, Validation loss: 0.010016181381855945\n","Epoch 150: Train acc: 0.6920441509316962, Train loss: 0.010309340928346802 |Validation acc: 0.6868127893518519, Validation loss: 0.010224049280809366\n","Epoch 151: Train acc: 0.6921681704027532, Train loss: 0.010243450106295704 |Validation acc: 0.6884765625, Validation loss: 0.009998738972984188\n","Epoch 152: Train acc: 0.6894707469072644, Train loss: 0.010280292729905167 |Validation acc: 0.6859447337962963, Validation loss: 0.00997211998300931\n","Epoch 153: Train acc: 0.676828512076396, Train loss: 0.010399373680717956 |Validation acc: 0.6707537615740741, Validation loss: 0.010198622292532234\n","Epoch 154: Train acc: 0.6853703531454438, Train loss: 0.009919263194494767 |Validation acc: 0.6813151041666666, Validation loss: 0.009983427731392115\n","Epoch 155: Train acc: 0.6942377453260162, Train loss: 0.010144311292179879 |Validation acc: 0.6877893518518519, Validation loss: 0.009931427777609414\n","Epoch 156: Train acc: 0.6794716770532974, Train loss: 0.009606402927666947 |Validation acc: 0.6738642939814815, Validation loss: 0.010145201456929261\n","Epoch 157: Train acc: 0.6893389762192664, Train loss: 0.00999165681337258 |Validation acc: 0.6846788194444444, Validation loss: 0.009761141147464514\n","Epoch 158: Train acc: 0.6901683564319598, Train loss: 0.00999138297137282 |Validation acc: 0.6851490162037037, Validation loss: 0.010096596283782882\n","Epoch 159: Train acc: 0.6896490248969088, Train loss: 0.010078697719608464 |Validation acc: 0.6852936921296297, Validation loss: 0.010108368795293242\n","Epoch 160: Train acc: 0.6927495116733328, Train loss: 0.009999797302256794 |Validation acc: 0.6872829861111112, Validation loss: 0.010389666950457262\n","Epoch 161: Train acc: 0.6874941865872942, Train loss: 0.009974265008203089 |Validation acc: 0.6820384837962963, Validation loss: 0.009835938616304794\n","Epoch 162: Train acc: 0.686036957802375, Train loss: 0.009841431612121245 |Validation acc: 0.6803023726851852, Validation loss: 0.009947584709843471\n","Epoch 163: Train acc: 0.6877732303971723, Train loss: 0.010024080308601923 |Validation acc: 0.6818938078703703, Validation loss: 0.010089138881317189\n","Epoch 164: Train acc: 0.6905636684959539, Train loss: 0.010312445955047003 |Validation acc: 0.6846426504629629, Validation loss: 0.009743512963229454\n","Epoch 165: Train acc: 0.6938114283942579, Train loss: 0.00997262820463285 |Validation acc: 0.6883680555555556, Validation loss: 0.01007673603645595\n","Epoch 166: Train acc: 0.6917651071218182, Train loss: 0.009584629064624803 |Validation acc: 0.6865596064814815, Validation loss: 0.009807955563477399\n","Epoch 167: Train acc: 0.6888118934672743, Train loss: 0.009513489299561573 |Validation acc: 0.6850766782407407, Validation loss: 0.009938752256577022\n","Epoch 168: Train acc: 0.6923619508262797, Train loss: 0.009856006608673478 |Validation acc: 0.6868851273148148, Validation loss: 0.00965232662414408\n","Epoch 169: Train acc: 0.69097448299383, Train loss: 0.009882574049805675 |Validation acc: 0.6865234375, Validation loss: 0.009654982154359847\n","Epoch 170: Train acc: 0.6935323845843797, Train loss: 0.010174642054458047 |Validation acc: 0.6861617476851852, Validation loss: 0.009957834978750977\n","Epoch 171: Train acc: 0.6898428053204353, Train loss: 0.009979414974701334 |Validation acc: 0.6841724537037037, Validation loss: 0.010126307740039262\n","Epoch 172: Train acc: 0.6918426192912287, Train loss: 0.009898939324703168 |Validation acc: 0.6863787615740741, Validation loss: 0.009804168870832871\n","Epoch 173: Train acc: 0.6938811893467275, Train loss: 0.009747231719070265 |Validation acc: 0.6876085069444444, Validation loss: 0.00970453436787652\n","Epoch 174: Train acc: 0.6899590735745512, Train loss: 0.009823124862665681 |Validation acc: 0.685546875, Validation loss: 0.00959841931620143\n","Epoch 175: Train acc: 0.6917806095557002, Train loss: 0.009673034951908828 |Validation acc: 0.6869212962962963, Validation loss: 0.009728345238584306\n","Epoch 176: Train acc: 0.6948190865965956, Train loss: 0.00969926249622768 |Validation acc: 0.6887659143518519, Validation loss: 0.009807701118964736\n","Epoch 177: Train acc: 0.6908659659566552, Train loss: 0.009953537265678939 |Validation acc: 0.6863787615740741, Validation loss: 0.009783040027435349\n","Epoch 178: Train acc: 0.6900365857439618, Train loss: 0.00998240532643695 |Validation acc: 0.6840639467592593, Validation loss: 0.009815534404050615\n","Epoch 179: Train acc: 0.6906566830992465, Train loss: 0.009855793462928041 |Validation acc: 0.6847149884259259, Validation loss: 0.009784587124882138\n","Epoch 180: Train acc: 0.6922611850060459, Train loss: 0.009840521980795556 |Validation acc: 0.6869936342592593, Validation loss: 0.009800102324045377\n","Epoch 181: Train acc: 0.6897110346324373, Train loss: 0.009925201539370267 |Validation acc: 0.6847873263888888, Validation loss: 0.009928959255999379\n","Epoch 182: Train acc: 0.6894397420395002, Train loss: 0.009658126026469363 |Validation acc: 0.6852575231481481, Validation loss: 0.009682769200402569\n","Epoch 183: Train acc: 0.6941059746380182, Train loss: 0.01026486423839359 |Validation acc: 0.6890552662037037, Validation loss: 0.009596468960916076\n","Epoch 184: Train acc: 0.69433851114625, Train loss: 0.010268211567177485 |Validation acc: 0.6886935763888888, Validation loss: 0.009973913179682872\n","Epoch 185: Train acc: 0.6928812823613307, Train loss: 0.010069773703791444 |Validation acc: 0.6880425347222222, Validation loss: 0.00989502781825223\n","Epoch 186: Train acc: 0.6964390909372772, Train loss: 0.009890990135555628 |Validation acc: 0.6911168981481481, Validation loss: 0.009681182852683682\n","Epoch 187: Train acc: 0.6960437788732831, Train loss: 0.00967440404721953 |Validation acc: 0.6907552083333334, Validation loss: 0.009598364774414092\n","Epoch 188: Train acc: 0.6922844386568692, Train loss: 0.009734359257564346 |Validation acc: 0.6859447337962963, Validation loss: 0.00985153006024946\n","Epoch 189: Train acc: 0.6958887545344619, Train loss: 0.00982799939258516 |Validation acc: 0.6911530671296297, Validation loss: 0.009773649378936704\n","Epoch 190: Train acc: 0.6935091309335566, Train loss: 0.010110868707586644 |Validation acc: 0.6879340277777778, Validation loss: 0.009639375172251455\n","Epoch 191: Train acc: 0.6957957399311692, Train loss: 0.009200005844589156 |Validation acc: 0.6893084490740741, Validation loss: 0.009328466232794196\n","Epoch 192: Train acc: 0.6927572628902737, Train loss: 0.009379362237006868 |Validation acc: 0.6903573495370371, Validation loss: 0.009944186606706958\n","Epoch 193: Train acc: 0.6919123802436983, Train loss: 0.009218450675743358 |Validation acc: 0.6872468171296297, Validation loss: 0.009418050366113907\n","Epoch 194: Train acc: 0.688625864260689, Train loss: 0.010200940318494063 |Validation acc: 0.6849681712962963, Validation loss: 0.009758507778304311\n","Epoch 195: Train acc: 0.6923929556940439, Train loss: 0.009491859960787065 |Validation acc: 0.6871744791666666, Validation loss: 0.009630955149798214\n","Epoch 196: Train acc: 0.6957802374972871, Train loss: 0.009837028401895518 |Validation acc: 0.6896339699074074, Validation loss: 0.01007698089138602\n","Epoch 197: Train acc: 0.6950748767556506, Train loss: 0.009274416444242796 |Validation acc: 0.6894892939814815, Validation loss: 0.009941585031711117\n","Epoch 198: Train acc: 0.692904536012154, Train loss: 0.00982012264762151 |Validation acc: 0.6881510416666666, Validation loss: 0.009805126933696008\n","Epoch 199: Train acc: 0.6944470281834249, Train loss: 0.009391429129357861 |Validation acc: 0.6898148148148148, Validation loss: 0.00983320379240068\n","Epoch 200: Train acc: 0.6921139118841658, Train loss: 0.009490211171620367 |Validation acc: 0.6864510995370371, Validation loss: 0.009487630112665962\n","Epoch 201: Train acc: 0.6964003348525718, Train loss: 0.00971458842134993 |Validation acc: 0.6919487847222222, Validation loss: 0.009536613940982595\n","Epoch 202: Train acc: 0.6949353548507116, Train loss: 0.0100952882792259 |Validation acc: 0.6899233217592593, Validation loss: 0.009918364791547774\n","Epoch 203: Train acc: 0.6966638762285678, Train loss: 0.009765164778797226 |Validation acc: 0.6912615740740741, Validation loss: 0.009458889084859843\n","Epoch 204: Train acc: 0.6957182277617586, Train loss: 0.009370535587234207 |Validation acc: 0.6897786458333334, Validation loss: 0.009550026067303223\n","Epoch 205: Train acc: 0.6969274176045639, Train loss: 0.009559269427965762 |Validation acc: 0.6919487847222222, Validation loss: 0.009347874738928208\n","Epoch 206: Train acc: 0.6901373515641955, Train loss: 0.009636526671721869 |Validation acc: 0.6883680555555556, Validation loss: 0.009657964146300841\n","Epoch 207: Train acc: 0.6918426192912287, Train loss: 0.009647836027810632 |Validation acc: 0.6863787615740741, Validation loss: 0.00980592370226714\n","Epoch 208: Train acc: 0.6950283694540043, Train loss: 0.00950956491695424 |Validation acc: 0.6906467013888888, Validation loss: 0.009694035841395266\n","Epoch 209: Train acc: 0.6926952531547453, Train loss: 0.009808941009158727 |Validation acc: 0.6867766203703703, Validation loss: 0.009799319077614773\n","Epoch 210: Train acc: 0.6909589805599479, Train loss: 0.009381106635279269 |Validation acc: 0.6871744791666666, Validation loss: 0.009823334520787708\n","Epoch 211: Train acc: 0.6964778470219825, Train loss: 0.00989030662631113 |Validation acc: 0.6910083912037037, Validation loss: 0.009455148940380851\n","Epoch 212: Train acc: 0.6908969708244195, Train loss: 0.009531540834850657 |Validation acc: 0.6872468171296297, Validation loss: 0.009399318384305085\n","Epoch 213: Train acc: 0.6934703748488513, Train loss: 0.009580653890392548 |Validation acc: 0.6883318865740741, Validation loss: 0.009704881919774528\n","Epoch 214: Train acc: 0.6958344960158744, Train loss: 0.009465138998590078 |Validation acc: 0.6900318287037037, Validation loss: 0.00954038345183105\n","Epoch 215: Train acc: 0.6962220568629275, Train loss: 0.00980120136206334 |Validation acc: 0.6919487847222222, Validation loss: 0.009382861145448703\n","Epoch 216: Train acc: 0.6974700027904381, Train loss: 0.00953155957599024 |Validation acc: 0.6901765046296297, Validation loss: 0.009618256948556673\n","Epoch 217: Train acc: 0.6937106625740241, Train loss: 0.009544783213123326 |Validation acc: 0.6882957175925926, Validation loss: 0.009801145195988634\n","Epoch 218: Train acc: 0.6956174619415249, Train loss: 0.00970972642214079 |Validation acc: 0.6897424768518519, Validation loss: 0.00974605819044596\n","Epoch 219: Train acc: 0.6912922828884135, Train loss: 0.009491442629476064 |Validation acc: 0.6853298611111112, Validation loss: 0.01006294124917257\n","Epoch 220: Train acc: 0.6919201314606394, Train loss: 0.009553532234257645 |Validation acc: 0.6871021412037037, Validation loss: 0.009662249698980715\n","Epoch 221: Train acc: 0.6920441509316962, Train loss: 0.009963844289301233 |Validation acc: 0.6875723379629629, Validation loss: 0.009420334679303961\n","Epoch 222: Train acc: 0.6974079930549096, Train loss: 0.009679443430907207 |Validation acc: 0.6940465856481481, Validation loss: 0.009561553271349176\n","Epoch 223: Train acc: 0.6896102688122036, Train loss: 0.009693979235222281 |Validation acc: 0.6857638888888888, Validation loss: 0.009774705396484284\n","Epoch 224: Train acc: 0.689796298018789, Train loss: 0.009593631935413672 |Validation acc: 0.6875, Validation loss: 0.009379470660088677\n","Epoch 225: Train acc: 0.6919743899792268, Train loss: 0.009903740734746265 |Validation acc: 0.6871744791666666, Validation loss: 0.009721316417916858\n","Epoch 226: Train acc: 0.6979893343254892, Train loss: 0.009664999686585025 |Validation acc: 0.6917679398148148, Validation loss: 0.009172376777247169\n","Epoch 227: Train acc: 0.6922999410907512, Train loss: 0.00970062895509406 |Validation acc: 0.6865957754629629, Validation loss: 0.009569967408783358\n","Epoch 228: Train acc: 0.6942532477598983, Train loss: 0.008977666638172522 |Validation acc: 0.6902488425925926, Validation loss: 0.009287925618797408\n","Epoch 229: Train acc: 0.6959895203546956, Train loss: 0.010036977803892835 |Validation acc: 0.6905020254629629, Validation loss: 0.009508577809677368\n","Epoch 230: Train acc: 0.6963228226831613, Train loss: 0.009639092370071822 |Validation acc: 0.6918041087962963, Validation loss: 0.009376649275002034\n","Epoch 231: Train acc: 0.690323380770781, Train loss: 0.009424379112016554 |Validation acc: 0.6849681712962963, Validation loss: 0.009830612198723264\n","Epoch 232: Train acc: 0.6981288562304282, Train loss: 0.00912518791428792 |Validation acc: 0.6940465856481481, Validation loss: 0.00936530993350447\n","Epoch 233: Train acc: 0.6983458903047779, Train loss: 0.009696216500731799 |Validation acc: 0.6926721643518519, Validation loss: 0.009999112493444222\n","Epoch 234: Train acc: 0.698229622050662, Train loss: 0.009573700338275965 |Validation acc: 0.6928168402777778, Validation loss: 0.009384164498229056\n","Epoch 235: Train acc: 0.6973847394040864, Train loss: 0.00945786084670253 |Validation acc: 0.6893807870370371, Validation loss: 0.009240453081752673\n","Epoch 236: Train acc: 0.6940982234210771, Train loss: 0.009964171316176211 |Validation acc: 0.6884765625, Validation loss: 0.00965131267087219\n","Epoch 237: Train acc: 0.6960127740055189, Train loss: 0.00962764809035229 |Validation acc: 0.6914785879629629, Validation loss: 0.009507100057763321\n","Epoch 238: Train acc: 0.6979273245899607, Train loss: 0.009474571267811675 |Validation acc: 0.6926359953703703, Validation loss: 0.009549873684828642\n","Epoch 239: Train acc: 0.698113353796546, Train loss: 0.00965969123012588 |Validation acc: 0.6919487847222222, Validation loss: 0.00946610007097928\n","Epoch 240: Train acc: 0.6971444516789136, Train loss: 0.009471072619836169 |Validation acc: 0.6920934606481481, Validation loss: 0.009724280486043643\n","Epoch 241: Train acc: 0.6959430130530493, Train loss: 0.00957458147651983 |Validation acc: 0.6893084490740741, Validation loss: 0.009467706117414225\n","Epoch 242: Train acc: 0.6936253991876725, Train loss: 0.009740503138699499 |Validation acc: 0.6888382523148148, Validation loss: 0.009318196591962605\n","Epoch 243: Train acc: 0.6969584224723282, Train loss: 0.009640275368063493 |Validation acc: 0.6903211805555556, Validation loss: 0.009388267329288784\n","Epoch 244: Train acc: 0.6941059746380182, Train loss: 0.009285608024643155 |Validation acc: 0.6876808449074074, Validation loss: 0.009628871530404962\n","Epoch 245: Train acc: 0.6973537345363222, Train loss: 0.009521982879225906 |Validation acc: 0.6903573495370371, Validation loss: 0.009326247693915529\n","Epoch 246: Train acc: 0.6982063683998387, Train loss: 0.009538035700926751 |Validation acc: 0.6939019097222222, Validation loss: 0.009470921556274641\n","Epoch 247: Train acc: 0.6956174619415249, Train loss: 0.00961237079919888 |Validation acc: 0.6907190393518519, Validation loss: 0.009349091259005427\n","Epoch 248: Train acc: 0.6967258859640963, Train loss: 0.009899442084133625 |Validation acc: 0.6921296296296297, Validation loss: 0.009827564781371404\n","Epoch 249: Train acc: 0.6949508572845937, Train loss: 0.009495600427912676 |Validation acc: 0.6887297453703703, Validation loss: 0.00939808618304947\n","Epoch 250: Train acc: 0.6870446160047128, Train loss: 0.009546659394921818 |Validation acc: 0.6809534143518519, Validation loss: 0.009320635058383736\n","Epoch 251: Train acc: 0.6959817691377547, Train loss: 0.009360915384993222 |Validation acc: 0.6913700810185185, Validation loss: 0.009714009150453685\n","Epoch 252: Train acc: 0.69550894490435, Train loss: 0.009409326648903397 |Validation acc: 0.6912254050925926, Validation loss: 0.009562758125022098\n","Epoch 253: Train acc: 0.6904163953740737, Train loss: 0.009494881741205115 |Validation acc: 0.6849320023148148, Validation loss: 0.009546064021402987\n","Epoch 254: Train acc: 0.6984621585588937, Train loss: 0.009628344441208579 |Validation acc: 0.6946976273148148, Validation loss: 0.009328216084248721\n","Epoch 255: Train acc: 0.696415837286454, Train loss: 0.009508729071524934 |Validation acc: 0.6920211226851852, Validation loss: 0.008976882265587766\n","Epoch 256: Train acc: 0.6997411093541686, Train loss: 0.009185024929572815 |Validation acc: 0.6927445023148148, Validation loss: 0.00938626564762801\n","Epoch 257: Train acc: 0.6956872228939943, Train loss: 0.009463836786472613 |Validation acc: 0.6901765046296297, Validation loss: 0.009460143127287973\n","Epoch 258: Train acc: 0.6963693299848076, Train loss: 0.009470046153817137 |Validation acc: 0.6928891782407407, Validation loss: 0.00946325959792521\n","Epoch 259: Train acc: 0.6977878026850215, Train loss: 0.009441903363277677 |Validation acc: 0.6920211226851852, Validation loss: 0.009154195978806439\n","Epoch 260: Train acc: 0.6962608129476328, Train loss: 0.009532595743516389 |Validation acc: 0.6911168981481481, Validation loss: 0.009451592524842711\n","Epoch 261: Train acc: 0.6949973645862401, Train loss: 0.009268956911786063 |Validation acc: 0.6921296296296297, Validation loss: 0.0096203272123144\n","Epoch 262: Train acc: 0.697718041732552, Train loss: 0.009484235910306345 |Validation acc: 0.6917679398148148, Validation loss: 0.009601254906720905\n","Epoch 263: Train acc: 0.6987334511518308, Train loss: 0.009491597957223742 |Validation acc: 0.6954571759259259, Validation loss: 0.009406658838771129\n","Epoch 264: Train acc: 0.6965786128422162, Train loss: 0.009360034335183549 |Validation acc: 0.6911530671296297, Validation loss: 0.009560062478155516\n","Epoch 265: Train acc: 0.6957879887142281, Train loss: 0.00929027060406056 |Validation acc: 0.6902850115740741, Validation loss: 0.009155105688202938\n","Epoch 266: Train acc: 0.6913852974917062, Train loss: 0.009646461613321517 |Validation acc: 0.6879701967592593, Validation loss: 0.009506461770171493\n","Epoch 267: Train acc: 0.697330480885499, Train loss: 0.00988859901597132 |Validation acc: 0.6909360532407407, Validation loss: 0.009380689923007605\n","Epoch 268: Train acc: 0.699787616655815, Train loss: 0.009170999017458421 |Validation acc: 0.6939742476851852, Validation loss: 0.009251926571009155\n","Epoch 269: Train acc: 0.6962918178153971, Train loss: 0.009204241937684111 |Validation acc: 0.6906828703703703, Validation loss: 0.009112666098494912\n","Epoch 270: Train acc: 0.6954159303010573, Train loss: 0.009352860795416888 |Validation acc: 0.6904658564814815, Validation loss: 0.009592689623509034\n","Epoch 271: Train acc: 0.6981366074473693, Train loss: 0.009601756776282316 |Validation acc: 0.6924913194444444, Validation loss: 0.00949473912241794\n","Epoch 272: Train acc: 0.6987799584534772, Train loss: 0.009336601872306638 |Validation acc: 0.6918764467592593, Validation loss: 0.00939495225702288\n","Epoch 273: Train acc: 0.6920286484978142, Train loss: 0.009163690943724146 |Validation acc: 0.6890914351851852, Validation loss: 0.009531064059872744\n","Epoch 274: Train acc: 0.6970049297739745, Train loss: 0.009382793520928225 |Validation acc: 0.6924189814814815, Validation loss: 0.009444368939614615\n","Epoch 275: Train acc: 0.6985706755960686, Train loss: 0.0089400171948934 |Validation acc: 0.6933232060185185, Validation loss: 0.009171980785521007\n","Epoch 276: Train acc: 0.6915558242644095, Train loss: 0.009480355922353816 |Validation acc: 0.6846788194444444, Validation loss: 0.009464603120555068\n","Epoch 277: Train acc: 0.7004542213127462, Train loss: 0.009594607423957803 |Validation acc: 0.6944444444444444, Validation loss: 0.009307595119101357\n","Epoch 278: Train acc: 0.6952919108300003, Train loss: 0.009228066932299458 |Validation acc: 0.6880425347222222, Validation loss: 0.009524303107751804\n","Epoch 279: Train acc: 0.6956949741109354, Train loss: 0.009479332034053276 |Validation acc: 0.6904658564814815, Validation loss: 0.009000433773321903\n","Epoch 280: Train acc: 0.6988264657551235, Train loss: 0.00901642353108114 |Validation acc: 0.6929976851851852, Validation loss: 0.009364465291636722\n","Epoch 281: Train acc: 0.6986946950671256, Train loss: 0.009500027794490405 |Validation acc: 0.6936125578703703, Validation loss: 0.00941875711558746\n","Epoch 282: Train acc: 0.6992295290360586, Train loss: 0.009209723730684875 |Validation acc: 0.6941189236111112, Validation loss: 0.009377108294743414\n","Epoch 283: Train acc: 0.6967878956996248, Train loss: 0.009090381040920446 |Validation acc: 0.6918402777777778, Validation loss: 0.009402175711672366\n","Epoch 284: Train acc: 0.6962375592968096, Train loss: 0.009504016548207234 |Validation acc: 0.6917679398148148, Validation loss: 0.009412601863749833\n","Epoch 285: Train acc: 0.6990667534802965, Train loss: 0.009514820934701655 |Validation acc: 0.6934678819444444, Validation loss: 0.009431863591926123\n","Epoch 286: Train acc: 0.699524075279819, Train loss: 0.009473964721876409 |Validation acc: 0.6957103587962963, Validation loss: 0.009161983088808527\n","Epoch 287: Train acc: 0.6980590952779586, Train loss: 0.009530281128488945 |Validation acc: 0.6919849537037037, Validation loss: 0.009436412960379344\n","Epoch 288: Train acc: 0.6978033051189036, Train loss: 0.009362939901329378 |Validation acc: 0.6928530092592593, Validation loss: 0.009070874580101992\n","Epoch 289: Train acc: 0.6996713484016991, Train loss: 0.008952569814111473 |Validation acc: 0.6942274305555556, Validation loss: 0.009193055291635258\n","Epoch 290: Train acc: 0.6990822559141785, Train loss: 0.009395549985792942 |Validation acc: 0.6938295717592593, Validation loss: 0.00918372205212624\n","Epoch 291: Train acc: 0.699276036337705, Train loss: 0.009301030175146876 |Validation acc: 0.6931061921296297, Validation loss: 0.009198198770656519\n","Epoch 292: Train acc: 0.6981366074473693, Train loss: 0.009423020957673427 |Validation acc: 0.6952401620370371, Validation loss: 0.009207656836408005\n","Epoch 293: Train acc: 0.6997488605711096, Train loss: 0.009469138675311288 |Validation acc: 0.6964337384259259, Validation loss: 0.009224844270852845\n","Epoch 294: Train acc: 0.7013688649117912, Train loss: 0.008943284544623968 |Validation acc: 0.6953125, Validation loss: 0.009096285164527573\n","Epoch 295: Train acc: 0.700299196973925, Train loss: 0.009223003046813722 |Validation acc: 0.6960720486111112, Validation loss: 0.009028818264178026\n","Epoch 296: Train acc: 0.701733172108021, Train loss: 0.009242340088448866 |Validation acc: 0.6961805555555556, Validation loss: 0.009500812509757652\n","Epoch 297: Train acc: 0.7037484885126964, Train loss: 0.009036839639115802 |Validation acc: 0.697265625, Validation loss: 0.008807549150854084\n","Epoch 298: Train acc: 0.6908504635227731, Train loss: 0.009045721707417898 |Validation acc: 0.6854021990740741, Validation loss: 0.009616246446967125\n","Epoch 299: Train acc: 0.7029733668185906, Train loss: 0.009403622492965455 |Validation acc: 0.6976634837962963, Validation loss: 0.009246885443509774\n","Epoch 300: Train acc: 0.7063528974048926, Train loss: 0.009589407446542728 |Validation acc: 0.6997251157407407, Validation loss: 0.008759324827151324\n","Epoch 301: Train acc: 0.6994233094595852, Train loss: 0.0091435720229339 |Validation acc: 0.6925998263888888, Validation loss: 0.009348225620926222\n","Epoch 302: Train acc: 0.7004309676619229, Train loss: 0.009227079990145803 |Validation acc: 0.6948784722222222, Validation loss: 0.009558153808536975\n","Epoch 303: Train acc: 0.6979118221560785, Train loss: 0.00917086836354094 |Validation acc: 0.6936125578703703, Validation loss: 0.009245069984219504\n","Epoch 304: Train acc: 0.7041903078783369, Train loss: 0.009214398521620459 |Validation acc: 0.6989655671296297, Validation loss: 0.00864062497243064\n","Epoch 305: Train acc: 0.703298917930115, Train loss: 0.009311783415588719 |Validation acc: 0.6964699074074074, Validation loss: 0.00914639414727511\n","Epoch 306: Train acc: 0.7031051375065885, Train loss: 0.009360583280061181 |Validation acc: 0.6961082175925926, Validation loss: 0.009524470050777764\n","Epoch 307: Train acc: 0.706399404706539, Train loss: 0.009016529155358981 |Validation acc: 0.6995804398148148, Validation loss: 0.00899012656108606\n","Epoch 308: Train acc: 0.7066396924317118, Train loss: 0.008943042318538406 |Validation acc: 0.7009548611111112, Validation loss: 0.009489255631204351\n","Epoch 309: Train acc: 0.7076163457662853, Train loss: 0.008948709287899008 |Validation acc: 0.7026186342592593, Validation loss: 0.009132803339671444\n","Epoch 310: Train acc: 0.7077403652373423, Train loss: 0.009108249489107453 |Validation acc: 0.7023292824074074, Validation loss: 0.008861021971943559\n","Epoch 311: Train acc: 0.7071590239667628, Train loss: 0.008957414981806845 |Validation acc: 0.7013527199074074, Validation loss: 0.00922491131087859\n","Epoch 312: Train acc: 0.7020897280873097, Train loss: 0.008920132589473967 |Validation acc: 0.6956741898148148, Validation loss: 0.008835838137620103\n","Epoch 313: Train acc: 0.7053607416364369, Train loss: 0.008969848991429726 |Validation acc: 0.6995442708333334, Validation loss: 0.009287427699757126\n","Epoch 314: Train acc: 0.7061281121136018, Train loss: 0.008983059701280398 |Validation acc: 0.7015335648148148, Validation loss: 0.009081604549224635\n","Epoch 315: Train acc: 0.7074303165596999, Train loss: 0.00925434331301854 |Validation acc: 0.7024739583333334, Validation loss: 0.009147179563106964\n","Epoch 316: Train acc: 0.7058568195206647, Train loss: 0.009490070977864527 |Validation acc: 0.6975549768518519, Validation loss: 0.009303535123352923\n","Epoch 317: Train acc: 0.7074613214274641, Train loss: 0.009004902574081715 |Validation acc: 0.7015335648148148, Validation loss: 0.008745634002550243\n","Epoch 318: Train acc: 0.701469630732025, Train loss: 0.008622596547482894 |Validation acc: 0.6955295138888888, Validation loss: 0.0087385180127152\n","Epoch 319: Train acc: 0.7061746194152482, Train loss: 0.009161656943511893 |Validation acc: 0.6997251157407407, Validation loss: 0.009197572095579405\n","Epoch 320: Train acc: 0.7076861067187549, Train loss: 0.009147050963211749 |Validation acc: 0.7010995370370371, Validation loss: 0.008968518667602884\n","Epoch 321: Train acc: 0.7092285988900258, Train loss: 0.00890574824391071 |Validation acc: 0.7036313657407407, Validation loss: 0.00854028646146066\n","Epoch 322: Train acc: 0.7073993116919356, Train loss: 0.008691234428446618 |Validation acc: 0.7013165509259259, Validation loss: 0.00873951225759854\n","Epoch 323: Train acc: 0.7068257216382973, Train loss: 0.00940481916233035 |Validation acc: 0.7008101851851852, Validation loss: 0.009141076697473268\n","Epoch 324: Train acc: 0.6991830217344123, Train loss: 0.009322757904558755 |Validation acc: 0.6945167824074074, Validation loss: 0.00917906551110594\n","Epoch 325: Train acc: 0.7036709763432859, Train loss: 0.009084624014463197 |Validation acc: 0.6988932291666666, Validation loss: 0.009190388569658075\n","Epoch 326: Train acc: 0.7013921185626143, Train loss: 0.009046803295573645 |Validation acc: 0.6945529513888888, Validation loss: 0.00922254740000766\n","Epoch 327: Train acc: 0.7078566334914581, Train loss: 0.009072057351481047 |Validation acc: 0.7034866898148148, Validation loss: 0.008809831903318844\n","Epoch 328: Train acc: 0.7070892630142932, Train loss: 0.008876967795182142 |Validation acc: 0.7005570023148148, Validation loss: 0.008773641462523478\n","Epoch 329: Train acc: 0.7052832294670264, Train loss: 0.008831129560678181 |Validation acc: 0.6994357638888888, Validation loss: 0.008968110652281197\n","Epoch 330: Train acc: 0.7058490683037237, Train loss: 0.008734637098967234 |Validation acc: 0.7002676504629629, Validation loss: 0.009201407602515614\n","Epoch 331: Train acc: 0.707438067776641, Train loss: 0.009178486220173825 |Validation acc: 0.7024377893518519, Validation loss: 0.008980208967096595\n","Epoch 332: Train acc: 0.7062366291507767, Train loss: 0.00888321218661168 |Validation acc: 0.6997974537037037, Validation loss: 0.009220402364450498\n","Epoch 333: Train acc: 0.7078721359253403, Train loss: 0.009150986037374603 |Validation acc: 0.7004123263888888, Validation loss: 0.009120909785934743\n","Epoch 334: Train acc: 0.7094146280966112, Train loss: 0.008662943245334556 |Validation acc: 0.7032335069444444, Validation loss: 0.008815276129060709\n","Epoch 335: Train acc: 0.7084379747620376, Train loss: 0.008950762851412466 |Validation acc: 0.7021846064814815, Validation loss: 0.008984553833555663\n","Epoch 336: Train acc: 0.7091123306359098, Train loss: 0.009135216777143828 |Validation acc: 0.7018590856481481, Validation loss: 0.008889957329739184\n","Epoch 337: Train acc: 0.7090735745512046, Train loss: 0.009194820167259133 |Validation acc: 0.7025101273148148, Validation loss: 0.009109659646209385\n","Epoch 338: Train acc: 0.7085232381483892, Train loss: 0.008909188546737772 |Validation acc: 0.7013527199074074, Validation loss: 0.009046639173460201\n","Epoch 339: Train acc: 0.7032524106284687, Train loss: 0.008748508772179926 |Validation acc: 0.6992910879629629, Validation loss: 0.0086870987537574\n","Epoch 340: Train acc: 0.7104765448175363, Train loss: 0.008929376689391073 |Validation acc: 0.7025462962962963, Validation loss: 0.008638473860477305\n","Epoch 341: Train acc: 0.7081511797352185, Train loss: 0.008771788309541053 |Validation acc: 0.7008101851851852, Validation loss: 0.009037309077510318\n","Epoch 342: Train acc: 0.7079031407931046, Train loss: 0.009102260525330062 |Validation acc: 0.7022569444444444, Validation loss: 0.009121347941425063\n","Epoch 343: Train acc: 0.7086240039686231, Train loss: 0.009298067082559761 |Validation acc: 0.7020037615740741, Validation loss: 0.008808452150997228\n","Epoch 344: Train acc: 0.7100734815366012, Train loss: 0.009097584263485158 |Validation acc: 0.7031973379629629, Validation loss: 0.009019530362391552\n","Epoch 345: Train acc: 0.7098409450283695, Train loss: 0.008769569175804272 |Validation acc: 0.7033420138888888, Validation loss: 0.008613882546979127\n","Epoch 346: Train acc: 0.7046166248100952, Train loss: 0.00912502876521594 |Validation acc: 0.7009910300925926, Validation loss: 0.009174225371032511\n","Epoch 347: Train acc: 0.707693857935696, Train loss: 0.009235046128258772 |Validation acc: 0.7012803819444444, Validation loss: 0.008990722265542216\n","Epoch 348: Train acc: 0.709399125662729, Train loss: 0.008850394502884601 |Validation acc: 0.7019675925925926, Validation loss: 0.008850815746026771\n","Epoch 349: Train acc: 0.7098409450283695, Train loss: 0.009397458861297333 |Validation acc: 0.7027633101851852, Validation loss: 0.009152417397264734\n","Epoch 350: Train acc: 0.710561808203888, Train loss: 0.008884743573171714 |Validation acc: 0.7049334490740741, Validation loss: 0.008761076432119402\n","Epoch 351: Train acc: 0.7084069698942734, Train loss: 0.00891783320585415 |Validation acc: 0.7028718171296297, Validation loss: 0.00863101561650501\n","Epoch 352: Train acc: 0.7054227513719654, Train loss: 0.008729580012550826 |Validation acc: 0.6988932291666666, Validation loss: 0.009045484901380999\n","Epoch 353: Train acc: 0.707693857935696, Train loss: 0.008909088348726623 |Validation acc: 0.7020037615740741, Validation loss: 0.00922505677683218\n","Epoch 354: Train acc: 0.7104222862989489, Train loss: 0.008984139605041162 |Validation acc: 0.7035590277777778, Validation loss: 0.009153784088270866\n","Epoch 355: Train acc: 0.7050429417418534, Train loss: 0.008720738932805396 |Validation acc: 0.6981698495370371, Validation loss: 0.008996051203498192\n","Epoch 356: Train acc: 0.7082674479893343, Train loss: 0.008968143969862681 |Validation acc: 0.7010995370370371, Validation loss: 0.008888625634491488\n","Epoch 357: Train acc: 0.7025005425851859, Train loss: 0.008782735421220034 |Validation acc: 0.6999782986111112, Validation loss: 0.008884270082694929\n","Epoch 358: Train acc: 0.7090580721173224, Train loss: 0.008997241574690541 |Validation acc: 0.7020399305555556, Validation loss: 0.008672389071932178\n","Epoch 359: Train acc: 0.7094301305304933, Train loss: 0.009027729494889607 |Validation acc: 0.7033058449074074, Validation loss: 0.008866179547927589\n","Epoch 360: Train acc: 0.7115229591045794, Train loss: 0.008889644064744299 |Validation acc: 0.7047164351851852, Validation loss: 0.008750066876229043\n","Epoch 361: Train acc: 0.7089495550801476, Train loss: 0.00895828674049932 |Validation acc: 0.7036313657407407, Validation loss: 0.008569672184883\n","Epoch 362: Train acc: 0.7110578860881158, Train loss: 0.008789781881745031 |Validation acc: 0.7048611111111112, Validation loss: 0.008838301099621268\n","Epoch 363: Train acc: 0.7101819985737761, Train loss: 0.0088723368959319 |Validation acc: 0.7034143518518519, Validation loss: 0.008786704868647527\n","Epoch 364: Train acc: 0.7112981738132886, Train loss: 0.008965432426950255 |Validation acc: 0.7032696759259259, Validation loss: 0.008673032239985926\n","Epoch 365: Train acc: 0.7087402722227389, Train loss: 0.008884662444473905 |Validation acc: 0.7031611689814815, Validation loss: 0.009066166209736812\n","Epoch 366: Train acc: 0.7081279260843952, Train loss: 0.00888532334703742 |Validation acc: 0.7005208333333334, Validation loss: 0.009517760065077452\n","Epoch 367: Train acc: 0.7125771246085636, Train loss: 0.008812296600841008 |Validation acc: 0.7067780671296297, Validation loss: 0.0086430365451852\n","Epoch 368: Train acc: 0.7125306173069171, Train loss: 0.008899681521607259 |Validation acc: 0.7067057291666666, Validation loss: 0.008845498321787939\n","Epoch 369: Train acc: 0.7077326140204012, Train loss: 0.008687913621629337 |Validation acc: 0.7023654513888888, Validation loss: 0.008858928578499516\n","Epoch 370: Train acc: 0.7138560754038384, Train loss: 0.008943533689303196 |Validation acc: 0.7064525462962963, Validation loss: 0.00878737077534265\n","Epoch 371: Train acc: 0.7107013301088271, Train loss: 0.009083681358494284 |Validation acc: 0.7052589699074074, Validation loss: 0.008674431919018\n","Epoch 372: Train acc: 0.7098254425944873, Train loss: 0.008895043326536255 |Validation acc: 0.7037398726851852, Validation loss: 0.008827160834542058\n","Epoch 373: Train acc: 0.7142513874678325, Train loss: 0.008699057424076189 |Validation acc: 0.70703125, Validation loss: 0.008690768186809932\n","Epoch 374: Train acc: 0.7057948097851363, Train loss: 0.008879773087318688 |Validation acc: 0.7001229745370371, Validation loss: 0.008646540708552482\n","Epoch 375: Train acc: 0.7120035345549252, Train loss: 0.00917728477467172 |Validation acc: 0.7067418981481481, Validation loss: 0.00874061547067757\n","Epoch 376: Train acc: 0.7100114718010727, Train loss: 0.00834380659600858 |Validation acc: 0.7033420138888888, Validation loss: 0.008500837998669207\n","Epoch 377: Train acc: 0.7098641986791926, Train loss: 0.00872346634758244 |Validation acc: 0.7043185763888888, Validation loss: 0.008933572911101915\n","Epoch 378: Train acc: 0.7133367438687874, Train loss: 0.00880185824691785 |Validation acc: 0.7059823495370371, Validation loss: 0.008482917202277335\n","Epoch 379: Train acc: 0.7129181781539702, Train loss: 0.008638362451359762 |Validation acc: 0.7059461805555556, Validation loss: 0.008806099516176549\n","Epoch 380: Train acc: 0.7115694664062258, Train loss: 0.009011639809948931 |Validation acc: 0.7058015046296297, Validation loss: 0.008695961576568665\n","Epoch 381: Train acc: 0.7117012370942238, Train loss: 0.008812008678459892 |Validation acc: 0.7059461805555556, Validation loss: 0.008629009953232963\n","Epoch 382: Train acc: 0.7019347037484885, Train loss: 0.009139664022069569 |Validation acc: 0.6969762731481481, Validation loss: 0.008906175960712024\n","Epoch 383: Train acc: 0.703562459306111, Train loss: 0.008950312792541852 |Validation acc: 0.6999059606481481, Validation loss: 0.008837584084872632\n","Epoch 384: Train acc: 0.713933587573249, Train loss: 0.008745825356176504 |Validation acc: 0.7081524884259259, Validation loss: 0.008425228080079401\n","Epoch 385: Train acc: 0.7119647784702198, Train loss: 0.008643956266299376 |Validation acc: 0.7048611111111112, Validation loss: 0.00886483510226586\n","Epoch 386: Train acc: 0.7136157876786655, Train loss: 0.00868781310788049 |Validation acc: 0.7082609953703703, Validation loss: 0.008823767142060823\n","Epoch 387: Train acc: 0.7062521315846588, Train loss: 0.008609314555528874 |Validation acc: 0.7017505787037037, Validation loss: 0.009060912194885645\n","Epoch 388: Train acc: 0.7130421976250271, Train loss: 0.008773705426006626 |Validation acc: 0.7065248842592593, Validation loss: 0.009018989836725265\n","Epoch 389: Train acc: 0.7128019098998543, Train loss: 0.008701576796036977 |Validation acc: 0.7060185185185185, Validation loss: 0.008589431576469488\n","Epoch 390: Train acc: 0.712251573497039, Train loss: 0.008537979646605227 |Validation acc: 0.7060185185185185, Validation loss: 0.008949934066900603\n","Epoch 391: Train acc: 0.7113601835488171, Train loss: 0.008555907045853068 |Validation acc: 0.7046440972222222, Validation loss: 0.00872127145517739\n","Epoch 392: Train acc: 0.7107245837596503, Train loss: 0.008847416677713969 |Validation acc: 0.7038845486111112, Validation loss: 0.008959819870180167\n","Epoch 393: Train acc: 0.7136467925464298, Train loss: 0.008681994629332945 |Validation acc: 0.7058738425925926, Validation loss: 0.008595597499826763\n","Epoch 394: Train acc: 0.7114144420674046, Train loss: 0.008376606594279232 |Validation acc: 0.7059823495370371, Validation loss: 0.00872328910819125\n","Epoch 395: Train acc: 0.7107633398443556, Train loss: 0.008318164352001485 |Validation acc: 0.7058376736111112, Validation loss: 0.008807540504339231\n","Epoch 396: Train acc: 0.7097711840758999, Train loss: 0.00844799989878645 |Validation acc: 0.7060546875, Validation loss: 0.008899239646353778\n","Epoch 397: Train acc: 0.7132049731807893, Train loss: 0.009051342774597093 |Validation acc: 0.705078125, Validation loss: 0.008457003899183932\n","Epoch 398: Train acc: 0.7121043003751589, Train loss: 0.008439318162253684 |Validation acc: 0.7067418981481481, Validation loss: 0.008382472924014846\n","Epoch 399: Train acc: 0.7127399001643258, Train loss: 0.008698361454592348 |Validation acc: 0.7055844907407407, Validation loss: 0.008368422680061853\n","Epoch 400: Train acc: 0.712763153815149, Train loss: 0.008888361051136998 |Validation acc: 0.7083333333333334, Validation loss: 0.008831118053179068\n","Epoch 401: Train acc: 0.7107168325427092, Train loss: 0.008528490306931142 |Validation acc: 0.7042824074074074, Validation loss: 0.008831839820574582\n","Epoch 402: Train acc: 0.7109803739187053, Train loss: 0.008834191826683433 |Validation acc: 0.7050419560185185, Validation loss: 0.008799955724857372\n","Epoch 403: Train acc: 0.7102517595262456, Train loss: 0.00871956536549113 |Validation acc: 0.7024377893518519, Validation loss: 0.008860172804041548\n","Epoch 404: Train acc: 0.7127011440796205, Train loss: 0.00871855670998 |Validation acc: 0.7052589699074074, Validation loss: 0.008839184144036486\n","Epoch 405: Train acc: 0.7140110997426596, Train loss: 0.009042316695360207 |Validation acc: 0.7071035879629629, Validation loss: 0.009034910125282071\n","Epoch 406: Train acc: 0.713414256038198, Train loss: 0.00852441741222687 |Validation acc: 0.7059100115740741, Validation loss: 0.008657174489601828\n","Epoch 407: Train acc: 0.7156233528664, Train loss: 0.008863810290242559 |Validation acc: 0.7085503472222222, Validation loss: 0.008788026232294495\n","Epoch 408: Train acc: 0.7098874523300158, Train loss: 0.008423123652397349 |Validation acc: 0.7030888310185185, Validation loss: 0.008679445530357011\n","Epoch 409: Train acc: 0.713538275509255, Train loss: 0.0084832624265598 |Validation acc: 0.7072844328703703, Validation loss: 0.008785529826278591\n","Epoch 410: Train acc: 0.7131817195299662, Train loss: 0.00893387576227991 |Validation acc: 0.7067057291666666, Validation loss: 0.008734555845217951\n","Epoch 411: Train acc: 0.7110423836542337, Train loss: 0.008565147390771513 |Validation acc: 0.7071397569444444, Validation loss: 0.008567436700493362\n","Epoch 412: Train acc: 0.7135537779431371, Train loss: 0.008753748370185273 |Validation acc: 0.7075014467592593, Validation loss: 0.008551895442952123\n","Epoch 413: Train acc: 0.7129569342386755, Train loss: 0.009012199074682125 |Validation acc: 0.7058376736111112, Validation loss: 0.008594656532398185\n","Epoch 414: Train acc: 0.7148559823892351, Train loss: 0.008628988679282875 |Validation acc: 0.7084780092592593, Validation loss: 0.00843541940621678\n","Epoch 415: Train acc: 0.7133832511704338, Train loss: 0.00886387125387213 |Validation acc: 0.7068142361111112, Validation loss: 0.008687299075163349\n","Epoch 416: Train acc: 0.7118407589991629, Train loss: 0.00899960643415635 |Validation acc: 0.7053313078703703, Validation loss: 0.008567148600552972\n","Epoch 417: Train acc: 0.7147707190028835, Train loss: 0.008611881319925366 |Validation acc: 0.708984375, Validation loss: 0.008655201211206902\n","Epoch 418: Train acc: 0.7109338666170589, Train loss: 0.009103807028609629 |Validation acc: 0.7043909143518519, Validation loss: 0.008843047572686738\n","Epoch 419: Train acc: 0.7100812327535423, Train loss: 0.008795775164979943 |Validation acc: 0.7045355902777778, Validation loss: 0.00863690117376826\n","Epoch 420: Train acc: 0.7144451678913589, Train loss: 0.00864279739633313 |Validation acc: 0.7065610532407407, Validation loss: 0.008400501095405185\n","Epoch 421: Train acc: 0.7109881251356462, Train loss: 0.008409468756949954 |Validation acc: 0.7065610532407407, Validation loss: 0.009062319659580993\n","Epoch 422: Train acc: 0.7143366508541841, Train loss: 0.008529200779622315 |Validation acc: 0.7057653356481481, Validation loss: 0.008422528347276836\n","Epoch 423: Train acc: 0.708872042910737, Train loss: 0.008724730248350196 |Validation acc: 0.7026186342592593, Validation loss: 0.008720485014752526\n","Epoch 424: Train acc: 0.7140498558273649, Train loss: 0.009013757567703503 |Validation acc: 0.7084056712962963, Validation loss: 0.008545065361547673\n","Epoch 425: Train acc: 0.7114144420674046, Train loss: 0.008871267097159248 |Validation acc: 0.7049696180555556, Validation loss: 0.008803704449525572\n","Epoch 426: Train acc: 0.7122670759309212, Train loss: 0.008677976451211716 |Validation acc: 0.7054398148148148, Validation loss: 0.008690636374957263\n","Epoch 427: Train acc: 0.7131274610113788, Train loss: 0.008867564812186519 |Validation acc: 0.7068142361111112, Validation loss: 0.008721537333954602\n","Epoch 428: Train acc: 0.7137863144513689, Train loss: 0.008452369065303078 |Validation acc: 0.7073567708333334, Validation loss: 0.008492198380992612\n","Epoch 429: Train acc: 0.7107788422782377, Train loss: 0.00848645564632971 |Validation acc: 0.7061993634259259, Validation loss: 0.008765906004307001\n","Epoch 430: Train acc: 0.7110268812203516, Train loss: 0.008541732693494515 |Validation acc: 0.7040292245370371, Validation loss: 0.009741475284707564\n","Epoch 431: Train acc: 0.7122128174123338, Train loss: 0.008704736922765344 |Validation acc: 0.7072482638888888, Validation loss: 0.008777795245495103\n","Epoch 432: Train acc: 0.7143754069388895, Train loss: 0.008694106632102978 |Validation acc: 0.7072120949074074, Validation loss: 0.008427691289419944\n","Epoch 433: Train acc: 0.7111121446067032, Train loss: 0.008624699123574072 |Validation acc: 0.7037037037037037, Validation loss: 0.008803315529080235\n","Epoch 434: Train acc: 0.7098254425944873, Train loss: 0.00884526096511002 |Validation acc: 0.7021846064814815, Validation loss: 0.008607612969077439\n","Epoch 435: Train acc: 0.7124376027036244, Train loss: 0.009031551440995331 |Validation acc: 0.7053674768518519, Validation loss: 0.00831969184745711\n","Epoch 436: Train acc: 0.7137785632344278, Train loss: 0.00855667856922622 |Validation acc: 0.7064525462962963, Validation loss: 0.008662761079191676\n","Epoch 437: Train acc: 0.7140188509596006, Train loss: 0.008654801677276853 |Validation acc: 0.7056929976851852, Validation loss: 0.008332905344366585\n","Epoch 438: Train acc: 0.7104687936005953, Train loss: 0.008594406249128746 |Validation acc: 0.7055844907407407, Validation loss: 0.008924762116612464\n","Epoch 439: Train acc: 0.7142048801661861, Train loss: 0.008236031832162413 |Validation acc: 0.7083695023148148, Validation loss: 0.008549939293154578\n","Epoch 440: Train acc: 0.7111896567761139, Train loss: 0.008722471037343454 |Validation acc: 0.7059823495370371, Validation loss: 0.008739388545765057\n","Epoch 441: Train acc: 0.7138483241868974, Train loss: 0.008330285726723093 |Validation acc: 0.7069589120370371, Validation loss: 0.00874246665807192\n","Epoch 442: Train acc: 0.7118950175177503, Train loss: 0.008924716749872448 |Validation acc: 0.7051866319444444, Validation loss: 0.008828810957821434\n","Epoch 443: Train acc: 0.7137088022819583, Train loss: 0.008659005882246116 |Validation acc: 0.7070674189814815, Validation loss: 0.008313995727976281\n","Epoch 444: Train acc: 0.7087170185719158, Train loss: 0.008812469948436898 |Validation acc: 0.7029441550925926, Validation loss: 0.008746615954390132\n","Epoch 445: Train acc: 0.7123523393172728, Train loss: 0.008520856987441771 |Validation acc: 0.7060908564814815, Validation loss: 0.008899417608418123\n","Epoch 446: Train acc: 0.7119492760363377, Train loss: 0.008622276008084902 |Validation acc: 0.7053674768518519, Validation loss: 0.008558096452574701\n","Epoch 447: Train acc: 0.7117865004805755, Train loss: 0.008619423347002985 |Validation acc: 0.7068504050925926, Validation loss: 0.008799976426748785\n","Epoch 448: Train acc: 0.7138560754038384, Train loss: 0.008519781097073319 |Validation acc: 0.7068142361111112, Validation loss: 0.008187361903079627\n","Epoch 449: Train acc: 0.7110656373050569, Train loss: 0.00831160203343705 |Validation acc: 0.7043185763888888, Validation loss: 0.008541919509341349\n","Epoch 450: Train acc: 0.7007255139056832, Train loss: 0.008910438305634772 |Validation acc: 0.6948423032407407, Validation loss: 0.008638398265825359\n","Epoch 451: Train acc: 0.7131739683130252, Train loss: 0.008205292636572829 |Validation acc: 0.7063440393518519, Validation loss: 0.008133779495446017\n","Epoch 452: Train acc: 0.7118407589991629, Train loss: 0.008015813377826787 |Validation acc: 0.7060908564814815, Validation loss: 0.008734162132053993\n","Epoch 453: Train acc: 0.7079108920100455, Train loss: 0.008446491448462937 |Validation acc: 0.7007378472222222, Validation loss: 0.00842428903954894\n","Epoch 454: Train acc: 0.7137785632344278, Train loss: 0.008023314078501495 |Validation acc: 0.7076822916666666, Validation loss: 0.008150139946534744\n","Epoch 455: Train acc: 0.7150187579449974, Train loss: 0.008078499068436973 |Validation acc: 0.7085503472222222, Validation loss: 0.008324902968271151\n","Epoch 456: Train acc: 0.7133832511704338, Train loss: 0.008336959089614031 |Validation acc: 0.7086588541666666, Validation loss: 0.008695209201961446\n","Epoch 457: Train acc: 0.7119802809041019, Train loss: 0.008066349293903976 |Validation acc: 0.70703125, Validation loss: 0.008364310787951999\n","Epoch 458: Train acc: 0.7135925340278424, Train loss: 0.008443131774127793 |Validation acc: 0.7076099537037037, Validation loss: 0.007917219779152943\n","Epoch 459: Train acc: 0.7140266021765417, Train loss: 0.00852370249709938 |Validation acc: 0.7081163194444444, Validation loss: 0.00842067701997683\n","Epoch 460: Train acc: 0.7149800018602921, Train loss: 0.008312340262719051 |Validation acc: 0.7079716435185185, Validation loss: 0.008282397420474435\n","Epoch 461: Train acc: 0.7147784702198245, Train loss: 0.008150002347078805 |Validation acc: 0.7075376157407407, Validation loss: 0.008531341515066937\n","Epoch 462: Train acc: 0.7131042073605556, Train loss: 0.007992313233776244 |Validation acc: 0.7051504629629629, Validation loss: 0.008204122642552596\n","Epoch 463: Train acc: 0.7151117725482901, Train loss: 0.008494003897654418 |Validation acc: 0.7081886574074074, Validation loss: 0.008068340441532632\n","Epoch 464: Train acc: 0.7150420115958206, Train loss: 0.008039792318405578 |Validation acc: 0.7069589120370371, Validation loss: 0.008066321032961902\n","Epoch 465: Train acc: 0.7160961770998047, Train loss: 0.008381229585578295 |Validation acc: 0.7090205439814815, Validation loss: 0.007932690685913409\n","Epoch 466: Train acc: 0.7152667968871113, Train loss: 0.008105906174250102 |Validation acc: 0.7089482060185185, Validation loss: 0.008083859127628388\n","Epoch 467: Train acc: 0.711988032121043, Train loss: 0.008262251431912802 |Validation acc: 0.7044632523148148, Validation loss: 0.008198981446238892\n","Epoch 468: Train acc: 0.7163752209096829, Train loss: 0.008310407777358322 |Validation acc: 0.7092013888888888, Validation loss: 0.007787491881650616\n","Epoch 469: Train acc: 0.7122670759309212, Train loss: 0.008290834140408375 |Validation acc: 0.7052589699074074, Validation loss: 0.00840812796610753\n","Epoch 470: Train acc: 0.7137088022819583, Train loss: 0.008083399895783126 |Validation acc: 0.7086226851851852, Validation loss: 0.008195304107307858\n","Epoch 471: Train acc: 0.7143676557219484, Train loss: 0.008369102998075658 |Validation acc: 0.7068504050925926, Validation loss: 0.007981660976889888\n","Epoch 472: Train acc: 0.7134762657737265, Train loss: 0.008877259630776213 |Validation acc: 0.7067057291666666, Validation loss: 0.008406366877954242\n","Epoch 473: Train acc: 0.715096270114408, Train loss: 0.008627445555156654 |Validation acc: 0.7094184027777778, Validation loss: 0.00833570775133765\n","Epoch 474: Train acc: 0.7105928130716522, Train loss: 0.008464797415828625 |Validation acc: 0.7043547453703703, Validation loss: 0.00846576385921315\n","Epoch 475: Train acc: 0.7072287849192324, Train loss: 0.008260419165289986 |Validation acc: 0.7010271990740741, Validation loss: 0.008021972333537056\n","Epoch 476: Train acc: 0.7117787492636344, Train loss: 0.008323768577303527 |Validation acc: 0.7055844907407407, Validation loss: 0.008357823813936566\n","Epoch 477: Train acc: 0.7117089883111648, Train loss: 0.008397420383962175 |Validation acc: 0.7038122106481481, Validation loss: 0.007808926539462424\n","Epoch 478: Train acc: 0.7066319412147707, Train loss: 0.008199171049144529 |Validation acc: 0.6994719328703703, Validation loss: 0.008052171861548364\n","Epoch 479: Train acc: 0.7115462127554026, Train loss: 0.008037880358758772 |Validation acc: 0.7056929976851852, Validation loss: 0.008037141102811084\n","Epoch 480: Train acc: 0.7114609493690509, Train loss: 0.008068601901363858 |Validation acc: 0.7041377314814815, Validation loss: 0.008553818820282066\n","Epoch 481: Train acc: 0.7079186432269866, Train loss: 0.008030721262091832 |Validation acc: 0.7023292824074074, Validation loss: 0.008143031565494592\n","Epoch 482: Train acc: 0.7039267665023409, Train loss: 0.008402731901764295 |Validation acc: 0.6978081597222222, Validation loss: 0.008764523133298365\n","Epoch 483: Train acc: 0.7138095681021921, Train loss: 0.008245966657692186 |Validation acc: 0.7075737847222222, Validation loss: 0.008402157835358373\n","Epoch 484: Train acc: 0.7111276470405854, Train loss: 0.008032515611173447 |Validation acc: 0.7043185763888888, Validation loss: 0.0080872627965918\n","Epoch 485: Train acc: 0.7100269742349549, Train loss: 0.008377913438828348 |Validation acc: 0.7042462384259259, Validation loss: 0.008426024186775884\n","Epoch 486: Train acc: 0.7092441013239078, Train loss: 0.0079355076230366 |Validation acc: 0.7015335648148148, Validation loss: 0.00811853909793169\n","Epoch 487: Train acc: 0.7103060180448331, Train loss: 0.008473934538701124 |Validation acc: 0.7041739004629629, Validation loss: 0.008301082512126124\n","Epoch 488: Train acc: 0.7141816265153629, Train loss: 0.008226987109892623 |Validation acc: 0.7080078125, Validation loss: 0.008041611768979613\n","Epoch 489: Train acc: 0.713546026726196, Train loss: 0.00797862881236331 |Validation acc: 0.7071397569444444, Validation loss: 0.008286845408109202\n","Epoch 490: Train acc: 0.715879143025455, Train loss: 0.008416727990829537 |Validation acc: 0.7097800925925926, Validation loss: 0.007976053505085784\n","Epoch 491: Train acc: 0.7077481164542834, Train loss: 0.007762196153203352 |Validation acc: 0.7022569444444444, Validation loss: 0.008027723784494912\n","Epoch 492: Train acc: 0.7140808606951291, Train loss: 0.00794776386128136 |Validation acc: 0.7072482638888888, Validation loss: 0.008265638303907053\n","Epoch 493: Train acc: 0.7091355842867331, Train loss: 0.007828360417918564 |Validation acc: 0.7022207754629629, Validation loss: 0.00810335655088705\n","Epoch 494: Train acc: 0.712894924503147, Train loss: 0.008132731135746668 |Validation acc: 0.7069589120370371, Validation loss: 0.008071756567280928\n","Epoch 495: Train acc: 0.7137475583666636, Train loss: 0.007926244527040719 |Validation acc: 0.7071759259259259, Validation loss: 0.008240721971957283\n","Epoch 496: Train acc: 0.7146156946640623, Train loss: 0.008297478594991326 |Validation acc: 0.7092013888888888, Validation loss: 0.00829241397577816\n","Epoch 497: Train acc: 0.7148249775214709, Train loss: 0.007938220996122243 |Validation acc: 0.7082609953703703, Validation loss: 0.008249482125436296\n","Epoch 498: Train acc: 0.7156156016494589, Train loss: 0.008187097386741674 |Validation acc: 0.7092375578703703, Validation loss: 0.008563910418214934\n","Epoch 499: Train acc: 0.7142048801661861, Train loss: 0.008005584972891238 |Validation acc: 0.7066333912037037, Validation loss: 0.008036585222758375\n","Epoch 500: Train acc: 0.7098176913775462, Train loss: 0.008257169116879827 |Validation acc: 0.7036313657407407, Validation loss: 0.00859138942862521\n","Epoch 501: Train acc: 0.7097556816420177, Train loss: 0.00832113098126535 |Validation acc: 0.7052951388888888, Validation loss: 0.008301947531856884\n","Epoch 502: Train acc: 0.7111431494744674, Train loss: 0.008096602699064403 |Validation acc: 0.7039568865740741, Validation loss: 0.008148893173673474\n","Epoch 503: Train acc: 0.71043003751589, Train loss: 0.00839548737490522 |Validation acc: 0.7041015625, Validation loss: 0.008434606425171215\n","Epoch 504: Train acc: 0.7114376957182278, Train loss: 0.008380091575026866 |Validation acc: 0.7058738425925926, Validation loss: 0.008366957123775467\n","Epoch 505: Train acc: 0.7093603695780237, Train loss: 0.007843292501370922 |Validation acc: 0.7022569444444444, Validation loss: 0.008087971200751975\n","Epoch 506: Train acc: 0.7109261154001179, Train loss: 0.008179047973329086 |Validation acc: 0.7040292245370371, Validation loss: 0.008233479993108339\n","Epoch 507: Train acc: 0.7097634328589588, Train loss: 0.008120697719882344 |Validation acc: 0.7030526620370371, Validation loss: 0.007808205552775004\n","Epoch 508: Train acc: 0.7123910954019781, Train loss: 0.008280019539073993 |Validation acc: 0.7060185185185185, Validation loss: 0.007950304715841655\n","Epoch 509: Train acc: 0.7128251635506775, Train loss: 0.008207212892452184 |Validation acc: 0.7061993634259259, Validation loss: 0.008110850053847676\n","Epoch 510: Train acc: 0.7149955042941741, Train loss: 0.0081586353909169 |Validation acc: 0.7071035879629629, Validation loss: 0.007748223938606127\n","Epoch 511: Train acc: 0.7133444950857285, Train loss: 0.008227202869282942 |Validation acc: 0.7059100115740741, Validation loss: 0.008154430200044586\n","Epoch 512: Train acc: 0.7147009580504139, Train loss: 0.008249093924900544 |Validation acc: 0.7104673032407407, Validation loss: 0.007754490642396606\n","Epoch 513: Train acc: 0.7116779834434006, Train loss: 0.0079921802453343 |Validation acc: 0.7057291666666666, Validation loss: 0.008438314151610261\n","Epoch 514: Train acc: 0.7114299445012867, Train loss: 0.008223621703916469 |Validation acc: 0.7062717013888888, Validation loss: 0.007924509313488131\n","Epoch 515: Train acc: 0.7147707190028835, Train loss: 0.008117437297036147 |Validation acc: 0.7097439236111112, Validation loss: 0.008200947142783719\n","Epoch 516: Train acc: 0.7129879391064398, Train loss: 0.008321369694164492 |Validation acc: 0.7059100115740741, Validation loss: 0.008032764368262198\n","Epoch 517: Train acc: 0.7108253495798841, Train loss: 0.00788938012443903 |Validation acc: 0.7046079282407407, Validation loss: 0.008507175985253928\n","Epoch 518: Train acc: 0.7112439152947013, Train loss: 0.008090490102906123 |Validation acc: 0.7053313078703703, Validation loss: 0.008367913274249222\n","Epoch 519: Train acc: 0.710298266827892, Train loss: 0.008046799237102005 |Validation acc: 0.7020760995370371, Validation loss: 0.008360721220646485\n","Epoch 520: Train acc: 0.7133599975196105, Train loss: 0.007824066207669565 |Validation acc: 0.7065248842592593, Validation loss: 0.008193519648346905\n","Epoch 521: Train acc: 0.7130732024927914, Train loss: 0.00785097336736494 |Validation acc: 0.7065610532407407, Validation loss: 0.007938023026513063\n","Epoch 522: Train acc: 0.7100579791027192, Train loss: 0.008297154248086873 |Validation acc: 0.7049696180555556, Validation loss: 0.007930995300218728\n","Epoch 523: Train acc: 0.7096394133879019, Train loss: 0.00851647162503212 |Validation acc: 0.7035951967592593, Validation loss: 0.00804990754415798\n","Epoch 524: Train acc: 0.7144994264099463, Train loss: 0.008136929605620463 |Validation acc: 0.7093822337962963, Validation loss: 0.007834428830144137\n","Epoch 525: Train acc: 0.715747372337457, Train loss: 0.008098583858465715 |Validation acc: 0.7092375578703703, Validation loss: 0.008238770661168132\n","Epoch 526: Train acc: 0.7131119585774967, Train loss: 0.007998342677613703 |Validation acc: 0.7055121527777778, Validation loss: 0.00787729912614367\n","Epoch 527: Train acc: 0.7142358850339503, Train loss: 0.008022422117432607 |Validation acc: 0.7064887152777778, Validation loss: 0.008234105263601778\n","Epoch 528: Train acc: 0.7148172263045298, Train loss: 0.008287146934847008 |Validation acc: 0.7080439814814815, Validation loss: 0.00798921085457464\n","Epoch 529: Train acc: 0.7138560754038384, Train loss: 0.008025362914931085 |Validation acc: 0.7080078125, Validation loss: 0.00841288224694482\n","Epoch 530: Train acc: 0.7122748271478622, Train loss: 0.008202604235091886 |Validation acc: 0.7060908564814815, Validation loss: 0.008411996234457066\n","Epoch 531: Train acc: 0.7158946454593371, Train loss: 0.007906453643900616 |Validation acc: 0.7094184027777778, Validation loss: 0.007987908947140597\n","Epoch 532: Train acc: 0.715104021331349, Train loss: 0.008057501239602617 |Validation acc: 0.7081524884259259, Validation loss: 0.00814751149099928\n","Epoch 533: Train acc: 0.7095619012184913, Train loss: 0.008113536708062453 |Validation acc: 0.7034143518518519, Validation loss: 0.008674691659909637\n","Epoch 534: Train acc: 0.7128639196353828, Train loss: 0.008192621438849705 |Validation acc: 0.7078631365740741, Validation loss: 0.008094640832134585\n","Epoch 535: Train acc: 0.7082209406876879, Train loss: 0.007811989608975211 |Validation acc: 0.7029441550925926, Validation loss: 0.008440447394329866\n","Epoch 536: Train acc: 0.7136700461972529, Train loss: 0.00801131485005183 |Validation acc: 0.7069950810185185, Validation loss: 0.007781470315365082\n","Epoch 537: Train acc: 0.7125693733916225, Train loss: 0.0084614439892309 |Validation acc: 0.7060908564814815, Validation loss: 0.008420826583957017\n","Epoch 538: Train acc: 0.7114997054537563, Train loss: 0.008230074422809817 |Validation acc: 0.7052228009259259, Validation loss: 0.008115966373899792\n","Epoch 539: Train acc: 0.7082907016401575, Train loss: 0.008225708694172365 |Validation acc: 0.7012803819444444, Validation loss: 0.00781017568346544\n","Epoch 540: Train acc: 0.7143444020711252, Train loss: 0.008008853862620338 |Validation acc: 0.7078993055555556, Validation loss: 0.008326673266016367\n","Epoch 541: Train acc: 0.715607850432518, Train loss: 0.007982186681538467 |Validation acc: 0.7092737268518519, Validation loss: 0.007990606136078385\n","Epoch 542: Train acc: 0.7093138622763774, Train loss: 0.008088733946340772 |Validation acc: 0.7042462384259259, Validation loss: 0.007791848413823089\n","Epoch 543: Train acc: 0.7149179921247636, Train loss: 0.00823356460942956 |Validation acc: 0.7100694444444444, Validation loss: 0.00791335068656911\n","Epoch 544: Train acc: 0.7156543577341643, Train loss: 0.00800734137817775 |Validation acc: 0.7077907986111112, Validation loss: 0.007967381070724493\n","Epoch 545: Train acc: 0.7160264161473351, Train loss: 0.008297521322523451 |Validation acc: 0.7092737268518519, Validation loss: 0.0077012340491223056\n","Epoch 546: Train acc: 0.7144374166744178, Train loss: 0.008095132497219418 |Validation acc: 0.7078269675925926, Validation loss: 0.00802255831230487\n","Epoch 547: Train acc: 0.715483830961461, Train loss: 0.008356815295912966 |Validation acc: 0.7087311921296297, Validation loss: 0.008140290031646232\n","Epoch 548: Train acc: 0.7106083155055344, Train loss: 0.008113146188892756 |Validation acc: 0.7053313078703703, Validation loss: 0.008310081638279716\n","Epoch 549: Train acc: 0.7135925340278424, Train loss: 0.008299276823432181 |Validation acc: 0.7073206018518519, Validation loss: 0.00818860384176875\n","Epoch 550: Train acc: 0.7138483241868974, Train loss: 0.008215549652732754 |Validation acc: 0.7056929976851852, Validation loss: 0.008006410677406041\n","Epoch 551: Train acc: 0.7065311753945369, Train loss: 0.008149430239352036 |Validation acc: 0.7000144675925926, Validation loss: 0.008103119905137122\n","Epoch 552: Train acc: 0.715359811490404, Train loss: 0.007657063901783672 |Validation acc: 0.7088035300925926, Validation loss: 0.007746877652407798\n","Epoch 553: Train acc: 0.7141583728645398, Train loss: 0.008170248668375549 |Validation acc: 0.7072844328703703, Validation loss: 0.00819861965229077\n","Epoch 554: Train acc: 0.7086317551855641, Train loss: 0.007901800769444788 |Validation acc: 0.7002314814814815, Validation loss: 0.008492632368330786\n","Epoch 555: Train acc: 0.7151195237652311, Train loss: 0.007877851173817802 |Validation acc: 0.7081886574074074, Validation loss: 0.007984147017105906\n","Epoch 556: Train acc: 0.7142203826000683, Train loss: 0.00794766349607432 |Validation acc: 0.7087311921296297, Validation loss: 0.007913640186947823\n","Epoch 557: Train acc: 0.7128639196353828, Train loss: 0.008097640978647755 |Validation acc: 0.7056929976851852, Validation loss: 0.008098029899093093\n","Epoch 558: Train acc: 0.7156543577341643, Train loss: 0.008076406327885982 |Validation acc: 0.7085865162037037, Validation loss: 0.007943746474922499\n","Epoch 559: Train acc: 0.711608222490931, Train loss: 0.008057094056805932 |Validation acc: 0.7053674768518519, Validation loss: 0.007883015596542718\n","Epoch 560: Train acc: 0.7121663101106874, Train loss: 0.007936255028056815 |Validation acc: 0.7069589120370371, Validation loss: 0.008176978614640033\n","Epoch 561: Train acc: 0.7135150218584317, Train loss: 0.007981057041835935 |Validation acc: 0.7082971643518519, Validation loss: 0.007891947429113156\n","Epoch 562: Train acc: 0.7132902365671411, Train loss: 0.008248565646678828 |Validation acc: 0.7062355324074074, Validation loss: 0.008389912031657265\n","Epoch 563: Train acc: 0.7149412457755868, Train loss: 0.008040991953079443 |Validation acc: 0.7068865740740741, Validation loss: 0.008041912589625673\n","Epoch 564: Train acc: 0.715367562707345, Train loss: 0.008039485980295065 |Validation acc: 0.7075376157407407, Validation loss: 0.008204347226707934\n","Epoch 565: Train acc: 0.7149955042941741, Train loss: 0.008061888858465925 |Validation acc: 0.7088396990740741, Validation loss: 0.00812805868969893\n","Epoch 566: Train acc: 0.7167240256720305, Train loss: 0.007879626243554873 |Validation acc: 0.7101417824074074, Validation loss: 0.008086765491754612\n","Epoch 567: Train acc: 0.7109183641831768, Train loss: 0.00829821227405784 |Validation acc: 0.7058738425925926, Validation loss: 0.008220098274331596\n","Epoch 568: Train acc: 0.7151195237652311, Train loss: 0.007970850084955287 |Validation acc: 0.7090928819444444, Validation loss: 0.008175069708045494\n","Epoch 569: Train acc: 0.7119802809041019, Train loss: 0.007817839646092907 |Validation acc: 0.7069227430555556, Validation loss: 0.00815541152386354\n","Epoch 570: Train acc: 0.7158636405915729, Train loss: 0.007768276339612393 |Validation acc: 0.7090928819444444, Validation loss: 0.007965835095977394\n","Epoch 571: Train acc: 0.7141738752984218, Train loss: 0.008212764593371873 |Validation acc: 0.7067057291666666, Validation loss: 0.008383263667315819\n","Epoch 572: Train acc: 0.714197128949245, Train loss: 0.008062309631801457 |Validation acc: 0.7078631365740741, Validation loss: 0.008094759226171437\n","Epoch 573: Train acc: 0.7111121446067032, Train loss: 0.008146443289569205 |Validation acc: 0.7063440393518519, Validation loss: 0.007968324350568988\n","Epoch 574: Train acc: 0.7112516665116423, Train loss: 0.007923349188170907 |Validation acc: 0.7038122106481481, Validation loss: 0.007920958751878903\n","Epoch 575: Train acc: 0.7155923479986358, Train loss: 0.008331782532750853 |Validation acc: 0.7095630787037037, Validation loss: 0.007830035899011335\n","Epoch 576: Train acc: 0.7140033485257186, Train loss: 0.008184306503851133 |Validation acc: 0.7085865162037037, Validation loss: 0.00793874467714781\n","Epoch 577: Train acc: 0.7163674696927418, Train loss: 0.008329983991335867 |Validation acc: 0.7084418402777778, Validation loss: 0.00788335090237794\n","Epoch 578: Train acc: 0.7159101478932193, Train loss: 0.008356931402406016 |Validation acc: 0.7087673611111112, Validation loss: 0.008505778955793124\n","Epoch 579: Train acc: 0.7166077574179146, Train loss: 0.008269993335461846 |Validation acc: 0.7089120370370371, Validation loss: 0.008413615414751168\n","Epoch 580: Train acc: 0.7155225870461662, Train loss: 0.007960739776282087 |Validation acc: 0.7086588541666666, Validation loss: 0.007961971858704259\n","Epoch 581: Train acc: 0.7137630608005456, Train loss: 0.007999769320092455 |Validation acc: 0.7078631365740741, Validation loss: 0.008091770862823335\n","Epoch 582: Train acc: 0.710693578891886, Train loss: 0.007845491119757162 |Validation acc: 0.7038483796296297, Validation loss: 0.008210838540216758\n","Epoch 583: Train acc: 0.7115617151892847, Train loss: 0.008014757615218398 |Validation acc: 0.7055121527777778, Validation loss: 0.007899522581704248\n","Epoch 584: Train acc: 0.7135150218584317, Train loss: 0.007921108878590719 |Validation acc: 0.7058376736111112, Validation loss: 0.007838174892805009\n","Epoch 585: Train acc: 0.70874802343968, Train loss: 0.00775050432683806 |Validation acc: 0.7004484953703703, Validation loss: 0.007839240008710887\n","Epoch 586: Train acc: 0.7159644064118067, Train loss: 0.007972046539452734 |Validation acc: 0.7084418402777778, Validation loss: 0.00824222594460898\n","Epoch 587: Train acc: 0.7131119585774967, Train loss: 0.008035919323663064 |Validation acc: 0.7081886574074074, Validation loss: 0.008140263246449722\n","Epoch 588: Train acc: 0.7157008650358107, Train loss: 0.007919789555839067 |Validation acc: 0.7103587962962963, Validation loss: 0.00793070450994443\n","Epoch 589: Train acc: 0.7082984528570986, Train loss: 0.008333494546837022 |Validation acc: 0.7026548032407407, Validation loss: 0.0076290217845891364\n","Epoch 590: Train acc: 0.7144839239760642, Train loss: 0.008261469169312575 |Validation acc: 0.7070674189814815, Validation loss: 0.007799347734095346\n","Epoch 591: Train acc: 0.7160496697981583, Train loss: 0.008073500136482786 |Validation acc: 0.7088035300925926, Validation loss: 0.008157512766532931\n","Epoch 592: Train acc: 0.716778284190618, Train loss: 0.008127955468343875 |Validation acc: 0.7103949652777778, Validation loss: 0.007847948099323479\n","Epoch 593: Train acc: 0.7145304312777107, Train loss: 0.008006167756283008 |Validation acc: 0.7080439814814815, Validation loss: 0.008004808906902413\n","Epoch 594: Train acc: 0.7164604842960345, Train loss: 0.008020898251924166 |Validation acc: 0.7101779513888888, Validation loss: 0.007741268924561824\n","Epoch 595: Train acc: 0.7163597184758007, Train loss: 0.008349847482401291 |Validation acc: 0.7091290509259259, Validation loss: 0.008291035699202106\n","Epoch 596: Train acc: 0.7150497628127616, Train loss: 0.008236297733739063 |Validation acc: 0.7079354745370371, Validation loss: 0.007885360588369344\n","Epoch 597: Train acc: 0.7164294794282703, Train loss: 0.008146158196391312 |Validation acc: 0.7101417824074074, Validation loss: 0.007830566719025153\n","Epoch 598: Train acc: 0.7148869872569994, Train loss: 0.008055237506706964 |Validation acc: 0.7103226273148148, Validation loss: 0.008154946649502354\n","Epoch 599: Train acc: 0.7134685145567854, Train loss: 0.007842640846398402 |Validation acc: 0.7071035879629629, Validation loss: 0.0077712724374977525\n","Epoch 600: Train acc: 0.7151427774160544, Train loss: 0.00831199063814469 |Validation acc: 0.7076099537037037, Validation loss: 0.00820489215059344\n","Finished Training\n","Total time elapsed: 1947.06 seconds\n"],"name":"stdout"},{"output_type":"display_data","data":{"image/png":"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\n","text/plain":["<Figure size 432x288 with 1 Axes>"]},"metadata":{"tags":[],"needs_background":"light"}},{"output_type":"display_data","data":{"image/png":"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\n","text/plain":["<Figure size 432x288 with 1 Axes>"]},"metadata":{"tags":[],"needs_background":"light"}},{"output_type":"stream","text":["Final Training Accuracy: 0.7151427774160544\n","Final Validation Accuracy: 0.7076099537037037\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"ymCsZH291prI"},"source":["## Part 4. Testing [12 pt]\n","\n","### Part (a) [2 pt]\n","\n","Compute and report the test accuracy."]},{"cell_type":"code","metadata":{"id":"0OkSbup91prJ","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1623458669778,"user_tz":240,"elapsed":662,"user":{"displayName":"Ryan Chen","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiEvvD9_5qPytyzMTOpfMHuCrDH24wjoy50AGq6UQ=s64","userId":"16436951824151695317"}},"outputId":"1d95a9a9-3df2-49c9-8c9e-0e0991e2c6e6"},"source":["test_loader = torch.utils.data.DataLoader(test_data, batch_size=64, shuffle=True)\n","test_acc = get_accuracy(model_5, test_loader)\n","print(\"The test accuracy of the best autoencoder model is\", test_acc*100, \"%\")"],"execution_count":null,"outputs":[{"output_type":"stream","text":["The test accuracy of the best autoencoder model is 70.53674768518519 %\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"UEe9yt6L1prM"},"source":["### Part (b) [4 pt]\n","\n","Based on the test accuracy alone, it is difficult to assess whether our model\n","is actually performing well. We don't know whether a high accuracy is due to\n","the simplicity of the problem, or if a poor accuracy is a result of the inherent\n","difficulty of the problem.\n","\n","It is therefore very important to be able to compare our model to at least one\n","alternative. In particular, we consider a simple **baseline**\n","model that is not very computationally expensive. Our neural network\n","should at least outperform this baseline model. If our network is not much\n","better than the baseline, then it is not doing well.\n","\n","For our data imputation problem, consider the following baseline model:\n","to predict a missing feature, the baseline model will look at the **most common value** of the feature in the training set. \n","\n","For example, if the feature \"marriage\" is missing, then this model's prediction will be the most common value for \"marriage\" in the training set, which happens to be \"Married-civ-spouse\".\n","\n","What would be the test accuracy of this baseline model?\n"]},{"cell_type":"code","metadata":{"id":"p45VHp011prN"},"source":["baseline = {}\n","for col in df_not_missing:\n","    baseline[col] = df[col].value_counts().idxmax()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"uaEbZI2wmau6","executionInfo":{"status":"ok","timestamp":1623457464515,"user_tz":240,"elapsed":112,"user":{"displayName":"Ryan Chen","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiEvvD9_5qPytyzMTOpfMHuCrDH24wjoy50AGq6UQ=s64","userId":"16436951824151695317"}},"outputId":"fe52d96c-b39f-4248-b651-49901f643624"},"source":["baseline"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["{'age': 0.2602739726027397,\n"," 'capgain': 0.0,\n"," 'caploss': 0.0,\n"," 'edu': ' HS-grad',\n"," 'marriage': ' Married-civ-spouse',\n"," 'occupation': ' Prof-specialty',\n"," 'relationship': ' Husband',\n"," 'sex': ' Male',\n"," 'work': ' Private',\n"," 'workhr': 0.3979591836734694,\n"," 'yredu': 0.5333333333333333}"]},"metadata":{"tags":[]},"execution_count":56}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"4BWEwG5YmZ72","executionInfo":{"status":"ok","timestamp":1623458378555,"user_tz":240,"elapsed":136,"user":{"displayName":"Ryan Chen","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiEvvD9_5qPytyzMTOpfMHuCrDH24wjoy50AGq6UQ=s64","userId":"16436951824151695317"}},"outputId":"915e1cd1-5a41-4f08-f2f3-044d8b0c6387"},"source":["baseline_acc = sum(df_not_missing[\"marriage\"] == baseline[\"marriage\"])/len(df_not_missing)\n","print(\"The baseline model accuracy of the \\\"marriage\\\" feature is\", baseline_acc*100, \"%\")"],"execution_count":null,"outputs":[{"output_type":"stream","text":["The baseline model accuracy of the \"marriage\" feature is 46.67947131974738 %\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"LBHylALZniix"},"source":["**Answer:**\n","\n","As shown in the code above, the test accuracy would vary depending on the feature with this baseline model due to its dependency on the most common value of each feature. For example, the baseline model accuracy of the \"marriage\" feature is `46.68%` because `46.68%` of values for the feature are \"Married-civ-spouse\", which is the most common value. "]},{"cell_type":"markdown","metadata":{"id":"QlHu0wxh1prP"},"source":["### Part (c) [1 pt]\n","\n","How does your test accuracy from part (a) compared to your basline test accuracy in part (b)?"]},{"cell_type":"markdown","metadata":{"id":"m1EjJ725oeNU"},"source":["**Answer:**\n","\n","The test accuracy of the autoencoder model is `70.54%`, which is much higher compared to the estimated test accuracy of taking the most common value, which is only `46.68%`. "]},{"cell_type":"markdown","metadata":{"id":"DfQPgu1Q1prS"},"source":["### Part (d) [1 pt]\n","\n","Look at the first item in your test data. \n","Do you think it is reasonable for a human\n","to be able to guess this person's education level\n","based on their other features? Explain."]},{"cell_type":"code","metadata":{"id":"3qbQ1vvT1prT","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1623460059713,"user_tz":240,"elapsed":131,"user":{"displayName":"Ryan Chen","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiEvvD9_5qPytyzMTOpfMHuCrDH24wjoy50AGq6UQ=s64","userId":"16436951824151695317"}},"outputId":"7a2ce039-5462-4ab8-8d1a-89daa749ed51"},"source":["get_features(test_data[0])"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["{'edu': 'Bachelors',\n"," 'marriage': 'Divorced',\n"," 'occupation': 'Prof-specialty',\n"," 'relationship': 'Not-in-family',\n"," 'sex': 'Male',\n"," 'work': 'Private'}"]},"metadata":{"tags":[]},"execution_count":114}]},{"cell_type":"markdown","metadata":{"id":"7Q3-U1AttMWL"},"source":["**Answer:**\n","\n","In my opinion it can be quite difficult to guess the person's education level based on their other features. Some speculations could be made based on the person's occupation. Since the person has an occupation in a professional specialty, I would guess that the person would at least have completed high school. Besides this connection, I cannot draw any other conclusions based on these features. "]},{"cell_type":"markdown","metadata":{"id":"p_d5uuAY1prZ"},"source":["### Part (e) [2 pt]\n","\n","What is your model's prediction of this person's education\n","level, given their other features?\n"]},{"cell_type":"code","metadata":{"id":"kBY5gKXR1pra","colab":{"base_uri":"https://localhost:8080/","height":35},"executionInfo":{"status":"ok","timestamp":1623460457384,"user_tz":240,"elapsed":129,"user":{"displayName":"Ryan Chen","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiEvvD9_5qPytyzMTOpfMHuCrDH24wjoy50AGq6UQ=s64","userId":"16436951824151695317"}},"outputId":"b9187569-1678-4e67-9a60-51944aa200d7"},"source":["test_edu = zero_out_feature(test_data[:1], \"edu\")[0]\n","predict = model_5(torch.from_numpy(test_edu))\n","get_feature(predict.detach().numpy(), \"edu\")"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"},"text/plain":["'Bachelors'"]},"metadata":{"tags":[]},"execution_count":117}]},{"cell_type":"markdown","metadata":{"id":"xXzHbUxsw6Ub"},"source":["**Answer:**\n","\n","The autoencoder model's prediction of this person's education level is \"Bachelors\", which is correct."]},{"cell_type":"markdown","metadata":{"id":"fdLNA0ce1prd"},"source":["### Part (f) [2 pt]\n","\n","What is the baseline model's prediction\n","of this person's education level?"]},{"cell_type":"code","metadata":{"id":"TXgoM9qk1prd","colab":{"base_uri":"https://localhost:8080/","height":35},"executionInfo":{"status":"ok","timestamp":1623460090470,"user_tz":240,"elapsed":148,"user":{"displayName":"Ryan Chen","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiEvvD9_5qPytyzMTOpfMHuCrDH24wjoy50AGq6UQ=s64","userId":"16436951824151695317"}},"outputId":"310ea1c5-bbea-4342-e95e-c8d3f10778f8"},"source":["baseline[\"edu\"]"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"},"text/plain":["' HS-grad'"]},"metadata":{"tags":[]},"execution_count":116}]},{"cell_type":"markdown","metadata":{"id":"Gzh3sLOuxixK"},"source":["**Answer:**\n","\n","The baseline model's prediction of this person's education level is \"HS-grad\", which is incorrect."]}]}